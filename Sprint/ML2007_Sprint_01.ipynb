{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint_1 機械学習フロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T03:20:11.634061Z",
     "start_time": "2020-11-10T03:20:06.597536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.1.0\n",
      "Keras Version: 2.2.4-tf\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas 1.1.3\n",
      "Scikit-Learn 0.23.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【事前工程】\n",
    "1. 事前学習で作成したベースラインモデルを展開する。 \n",
    "    1. データの前処理\n",
    "        1. csvファイルの読み出し\n",
    "        2. objectをlabel/one-hot変換して数値化\n",
    "        3. 異常値の処置\n",
    "        4. 欠損値の処置\n",
    "    2. 説明変数を選抜\n",
    "        1. 相関係数を算出\n",
    "        2. 高い相関性を4つ選択\n",
    "2. hold-out法ではなく、cross validationを行う。\n",
    "    1. scikit-learnのkFoldクラスを用いる\n",
    "    2. cross_val_scoreにて精度を確認する\n",
    "3. それ以降（学習・推定）は行わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:18.047282Z",
     "start_time": "2020-11-09T08:28:18.043293Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理（csvファイルの読み出し）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:22.849435Z",
     "start_time": "2020-11-09T08:28:22.845446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nacho\\\\Documents\\\\Coding\\\\DIC\\\\Sprint'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:27.562825Z",
     "start_time": "2020-11-09T08:28:24.907929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csvファイルの読み出し\n",
    "\n",
    "app_train = pd.read_csv('../Data/home_credit_defalut_risk_application_train.csv')\n",
    "app_test = pd.read_csv('../Data/home_credit_defalut_risk_application_test.csv')\n",
    "\n",
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理（object型をlabel/one-hot変換してint化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:27.959763Z",
     "start_time": "2020-11-09T08:28:27.563823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# objectをlabel/one-hot変換して数値化\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:29.390935Z",
     "start_time": "2020-11-09T08:28:28.164217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 243)\n",
      "Testing Features shape:  (48744, 239)\n",
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)\n",
    "\n",
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理（異常値の排除）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:31.300825Z",
     "start_time": "2020-11-09T08:28:31.232009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9274 anomalies in the test data out of 48744 entries\n"
     ]
    }
   ],
   "source": [
    "# Skipping anomalies\n",
    "\n",
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "print('There are %d anomalies in the test data out of %d entries' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理（欠損値の処置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:32.943430Z",
     "start_time": "2020-11-09T08:28:32.532529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>-9461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-16765.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>-19046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-19005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-19932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>0.145570</td>\n",
       "      <td>0.681632</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-9327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307507</th>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.115992</td>\n",
       "      <td>0.535276</td>\n",
       "      <td>-20775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307508</th>\n",
       "      <td>0.744026</td>\n",
       "      <td>0.535722</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>-14966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307509</th>\n",
       "      <td>0.505998</td>\n",
       "      <td>0.514163</td>\n",
       "      <td>0.661024</td>\n",
       "      <td>-11961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307510</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.708569</td>\n",
       "      <td>0.113922</td>\n",
       "      <td>-16856.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307511 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2        3\n",
       "0       0.083037  0.262949  0.139376  -9461.0\n",
       "1       0.311267  0.622246  0.535276 -16765.0\n",
       "2       0.505998  0.555912  0.729567 -19046.0\n",
       "3       0.505998  0.650442  0.535276 -19005.0\n",
       "4       0.505998  0.322738  0.535276 -19932.0\n",
       "...          ...       ...       ...      ...\n",
       "307506  0.145570  0.681632  0.535276  -9327.0\n",
       "307507  0.505998  0.115992  0.535276 -20775.0\n",
       "307508  0.744026  0.535722  0.218859 -14966.0\n",
       "307509  0.505998  0.514163  0.661024 -11961.0\n",
       "307510  0.734460  0.708569  0.113922 -16856.0\n",
       "\n",
       "[307511 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputer for handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy = 'median')\n",
    "\n",
    "X = np.array(app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']])\n",
    "y = np.array(app_train[['TARGET']])\n",
    "\n",
    "X = imputer.fit_transform(X)\n",
    "pd_X = pd.DataFrame(X)\n",
    "pd_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:33.953727Z",
     "start_time": "2020-11-09T08:28:33.949738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 4)\n",
      "Testing data shape:  (307511, 1)\n"
     ]
    }
   ],
   "source": [
    "# 欠損値の確認\n",
    "# print(pd_X.isnull().any())\n",
    "# Xとyデータの確認\n",
    "print('Training data shape: ', X.shape)\n",
    "print('Testing data shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題1】クロスバリデーション "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "「事前学習期間の課題で作成したベースラインモデルに対応したKFoldクラスによる訓練と交差検証（クロスバリデーション）で評価を行うパイプラインを作成する。」\n",
    "\n",
    "-----\n",
    "Point\n",
    "* ホールとアウト法ではなく、クロスバリデーション（交差検証法）を行う。\n",
    "    * ホールドアウト法：学習用と評価用で２分割\n",
    "    * クロスバリデーション（交差検証法）：学習用と評価用で２分割を１通り以上作成する。\n",
    "-----\n",
    "Workflow\n",
    "* scikit-learnのkFoldクラスを用いる。\n",
    "    * n_splits = 10回分割する。\n",
    "    * random_state = 1で固定\n",
    "    * 説明変数：X\n",
    "    * 目的変数：y\n",
    "* 交差検証をパイプラインを用いて検証する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T07:01:36.850619Z",
     "start_time": "2020-11-09T07:01:36.846630Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T07:01:39.727922Z",
     "start_time": "2020-11-09T07:01:39.609240Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [     0      1      2 ... 307508 307509 307510] TEST: [     6     19     20 ... 307488 307493 307495]\n",
      "TRAIN: [     0      2      3 ... 307508 307509 307510] TEST: [     1      4      8 ... 307471 307480 307501]\n",
      "TRAIN: [     0      1      2 ... 307508 307509 307510] TEST: [     3     18     30 ... 307474 307499 307503]\n",
      "TRAIN: [     0      1      2 ... 307508 307509 307510] TEST: [    22     29     38 ... 307473 307487 307504]\n",
      "TRAIN: [     0      1      2 ... 307508 307509 307510] TEST: [    21     42     56 ... 307475 307489 307502]\n",
      "TRAIN: [     0      1      2 ... 307508 307509 307510] TEST: [     9     10     15 ... 307483 307486 307492]\n",
      "TRAIN: [     0      1      2 ... 307507 307508 307509] TEST: [    12     16     25 ... 307484 307500 307510]\n",
      "TRAIN: [     0      1      2 ... 307507 307508 307510] TEST: [    23     37     55 ... 307497 307505 307509]\n",
      "TRAIN: [     0      1      3 ... 307506 307509 307510] TEST: [     2     11     35 ... 307494 307507 307508]\n",
      "TRAIN: [     1      2      3 ... 307508 307509 307510] TEST: [     0      5      7 ... 307491 307498 307506]\n"
     ]
    }
   ],
   "source": [
    "# 【参考】以下がhold-out法である。\n",
    "# 各Xとyのtrainとtestにsplitする。\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T06:57:42.381910Z",
     "start_time": "2020-11-09T06:57:40.128938Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919134596280229"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化器を作成\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# ロジスティック回帰器を作成\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# 標準化とロジスティック回帰を同時に行うパイプラインを作成\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# k-分割交差検証器を作成\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# k-分割交差検証を実行\n",
    "cv_results = cross_val_score(pipeline, #上記で定義したパイプライン\n",
    "                            X, # 特徴量行列\n",
    "                            y, # ターゲットベクトル\n",
    "                            cv=kf, # 交差検証手法\n",
    "                            scoring=\"accuracy\", # スコア関数\n",
    "                            n_jobs=-1) # 全てのCPUを利用\n",
    "\n",
    "# 平均値を計算\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題2】グリッドサーチ\n",
    "\n",
    "1. scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。\n",
    "2. ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。\n",
    "-----\n",
    "* グリッドサーチとは全てのパラメータの組み合わせを全て試して、最も評価精度の良いモノを探索する手法。\n",
    "-----\n",
    "* ベースラインモデル\n",
    "    * 説明変数：X\n",
    "    * 目的変数：y\n",
    "    * モデル：ロジスティック回帰\n",
    "* パラメータの調整対象\n",
    "    * C\n",
    "    * 正則化ペナルティ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### GridSearchCVを行うコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:28:53.844512Z",
     "start_time": "2020-11-09T08:28:36.960682Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n"
     ]
    }
   ],
   "source": [
    "# ライブラリーをロード\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ロジスティック回帰器を作成\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "# 正則化強度ハイパーパラメータの候補となる値の範囲を指定\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# 正則化ペナルティハイパーパラメータの候補となる値の範囲を指定\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# ハイパーパラメータの候補辞書を作成。\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# グリッド探索器を作成\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# グリッド探索器を訓練\n",
    "best_model = gridsearch.fit(X, y)\n",
    "\n",
    "print(\"Best Penalty:\", best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ベースラインモデルへのパラメーターの適応\n",
    "\n",
    "* 正則化ペナルティハイパーパラメータ: l2\n",
    "* 正則化強度ハイパーパラメータ: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:29:35.670612Z",
     "start_time": "2020-11-09T08:29:33.179277Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化器を作成\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# ロジスティック回帰器を作成（ハイパーパラメータをチューニング）\n",
    "logit = LogisticRegression(C=0.09, penalty='l1')\n",
    "\n",
    "# 標準化とロジスティック回帰を同時に行うパイプラインを作成\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# k-分割交差検証器を作成\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# k-分割交差検証を実行\n",
    "cv_results = cross_val_score(pipeline, #上記で定義したパイプライン\n",
    "                            X, # 特徴量行列\n",
    "                            y, # ターゲットベクトル\n",
    "                            cv=kf, # 交差検証手法\n",
    "                            scoring=\"accuracy\", # スコア関数\n",
    "                            n_jobs=-1) # 全てのCPUを利用\n",
    "\n",
    "# 平均値を計算\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T08:29:43.760967Z",
     "start_time": "2020-11-09T08:29:43.748999Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCVによる再学習\n",
    "best_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】Kaggle Notebooksからの調査\n",
    "\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 異常値の処置（適応済み）\n",
    "    * Anomalies（異常値）は原因は様々\n",
    "    * 最も安全な処置としては、欠損値として扱い、後の欠損値の処置に廻す。（平均値で補完する）\n",
    "* object型のint化（適応済み）\n",
    "    * 二値の場合はlabel encoding、二値以上の場合はone-hot encodingでカラム数を増やす。\n",
    "* 欠損値の処置（適応済み）\n",
    "    * SimpleImputerを用い、欠損値(NaN）に平均値を代入して補完する。\n",
    "* 相関係数行列（適応済み）\n",
    "    * 欠損値の処置の前に行う。\n",
    "* polynomical_features (多項式回帰）因果変数同士の組み合わせ \n",
    "    * 結果（目的変数）に対して、個々の説明変数の因果関係は乏しくとも、組み合わせにより相関性が向上する。\n",
    "* Light Gradient Boosting Machine (LightGBM)\n",
    "    * L・G・B・M！\n",
    "* 複数の学習アルゴリズムから最良のモデルを選択\n",
    "    * 一度のグリッド探索によって、ロジスティック回帰、ランダムフォレスト等の複数のモデルを比較検証する。\n",
    "    * 同時に上記複数のモデルから最良のハイパーパラメータを候補範囲から選択できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】高い汎化性能のモデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* グリッド探索器を用いて、複数のモデルとパラメータを比較検証する。\n",
    "    * ロジスティック回帰とランダムフォレスト回帰を用いたモデルの精度\n",
    "* ~~LightGBMを適応したモデルの精度~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グリッド探索器を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 29 candidates, totalling 145 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 145 out of 145 | elapsed: 35.8min finished\n"
     ]
    }
   ],
   "source": [
    "# ライブラリーをロード\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# パイプラインを作成\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "# 候補学習アルゴリズムとそのハイパーパラメータの辞書を作成\n",
    "search_space = [{\"classifier\": [LogisticRegression()],\n",
    "                \"classifier__penalty\": ['l1', 'l2'],\n",
    "                \"classifier__C\": np.logspace(0, 4, 10)},\n",
    "               {\"classifier\": [RandomForestClassifier()],\n",
    "               \"classifier__n_estimators\": [10, 100, 1000],\n",
    "               \"classifier__max_features\": [1, 2, 3]}]\n",
    "\n",
    "# グリッド探索器を作成\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# グリッド探索器を訓練\n",
    "best_model = gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('classifier', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'classifier': LogisticRegression(),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': False,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__l1_ratio': None,\n",
       " 'classifier__max_iter': 100,\n",
       " 'classifier__multi_class': 'auto',\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__solver': 'lbfgs',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9192711805397202"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ロジスティック回帰器を作成（ハイパーパラメータをチューニング）\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# 正則化強度ハイパーパラメータを指定\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# 正則化ペナルティハイパーパラメータを指定\n",
    "penalty = ['l2']\n",
    "\n",
    "# ハイパーパラメータの辞書を作成。\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "#グリッド探索器を作成\n",
    "gridsearch = GridSearchCV(logit, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# 二重交差検証を行い、平均値を表示\n",
    "cross_val_score(gridsearch, X, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論\n",
    "\n",
    "1. ロジスティック回帰（l1）を適応したcross_val_score：nan\n",
    "2. ロジスティック回帰（l2）を適応したcross_val_score：0.919\n",
    "\n",
    "ランダムフォレストとロジスティック回帰ではGridSearchCVはロジスティック回帰を選択した。\n",
    "パラメータ調整でも、同じロジスティック回帰でも正則化L1（ラッソ回帰）と正則化L2（リッジ回帰）とで、異なる結果が出た。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression [l1]</th>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression [l2]</th>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cross_val_score\n",
       "LogisticRegression [l1]             nan\n",
       "LogisticRegression [l2]           0.919"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasで表を作成\n",
    "\n",
    "list = [['nan'], [0.919]]\n",
    "df = pd.DataFrame(list)\n",
    "df.columns = ['cross_val_score']\n",
    "df.index = ['LogisticRegression [l1]', 'LogisticRegression [l2]']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】最終的なモデルの選定\n",
    "\n",
    "1. 最終的にこれは良いというモデルを選び、推定した結果をKaggleに提出してスコアを確認する。\n",
    "2. どういったアイデアを取り入れ、どの程度のスコアになったかを記載する。\n",
    "-----\n",
    "【解答】\n",
    "* ランダムフォレストとロジスティック回帰とで比較した場合はロジスティック回帰が好ましいと選択された。\n",
    "* ロジスティック回帰でのハイパーパラメータのチューニングでもC=1.0、ペナルティはL1（ラッソ）が良い結果が出ると判明した。\n",
    "    * そもそもL2はnan結果のため、精度の数値比較が乏しい結果であるが。\n",
    "* 標準化器を用いると、数値がnanになる場合がある。\n",
    "    * 原因は不明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressorのみをKaggleに提出\n",
    "gridsearch = GridSearchCV(logit, hyperparameters, cv=5, verbose=0, n_jobs=-1)\n",
    "Gridsearch.fit(gridsearch)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = GridSearch.predict_proba(X)\n",
    "\n",
    "# Make a submission dataframe\n",
    "submit = X[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "\n",
    "# Save the submission dataframe\n",
    "submit.to_csv('random_forest_baseline.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "jupyter_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
