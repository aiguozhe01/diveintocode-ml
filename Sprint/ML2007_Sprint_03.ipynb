{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint_03 機械学習スクラッチ　線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        \n",
    "        _gradient_descent(self, X)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def _gradient_descent(self, X, error):\n",
    "        \"\"\"\n",
    "        fitメソッドで呼び出された際に最急降下法による学習を行う。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self: class関数を引用する。\n",
    "\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "\n",
    "        error :\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        theta -= (sum(_linear_hypothesis(X, theta)-y)/m) * X\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def _linear_hypothesis(self, X, theta):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    \n",
    "    theta : 次の形のndarray, shape (n_samples, )\n",
    "    　パラメータ\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "    \n",
    "    \"\"\"\n",
    "    solution = theta[0] + np.sum(np.matmul(theta[1: ], X))\n",
    "    \n",
    "    return solution\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】仮定関数\n",
    "\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。\n",
    "\n",
    "$$\n",
    "h_\\theta(x) = \\theta_0x_0 + \\theta_1x_1+...+\\theta_jx_j+...+\\theta_nx_n.(x_0=1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【目的】\n",
    "\n",
    "* 上記の重回帰式を仮定する関数を作成する。\n",
    "\n",
    "### 【考察】\n",
    "\n",
    "* $\\begin{align}\\theta\\end{align}$ は直線の傾き（coefficients）を制御している。\n",
    "* $\\begin{align}x_0 = 1\\end{align}$ のため、切片は1である。\n",
    "* 行列 $\\begin{align}\\theta\\end{align}$ と行列 $\\begin{align}x_n\\end{align}$ の内積（np.dot or np.matmul）を算出する関数を作成する。\n",
    "* 内積を算出するため、引数Xの行数分の配列数thetaをnp.randomを用いて算出する。\n",
    "\n",
    "### 【工程順序】\n",
    "1. np.random（0-10の範囲）を用いて、Xの行数分の配列数thetaのarrayを構築\n",
    "2. x_train（ここでは引数X）を用いて$\\begin{align}h_\\theta\\end{align}$(x)を求める。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X, theta):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    \n",
    "    theta : 次の形のndarray, shape (n_samples, )\n",
    "    　パラメータ\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    Process\n",
    "    -------    \n",
    "    'theta' is the coefficients.\n",
    "    there are n independent variables.\n",
    "    \n",
    "    パラメータが２つしかない場合\n",
    "    \n",
    "    def hypothesis(theta, X):\n",
    "        return theta[0] + theta[1]*X\n",
    "    def cost_calc(theta, X, y):\n",
    "        return (1/2*m) * np.sum((hypothesis(theta, X) - y)**2)\n",
    "    \n",
    "    m = len(X) # number_of_training_data\n",
    "    def gradient_descent(theta, X, y, epoch, alpha):\n",
    "        cost = []\n",
    "        i = 0\n",
    "        while i < epoch:\n",
    "            hx = hypothesis(theta, X)\n",
    "            theta[0] -= alpha * (sum(hx-y)/m)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    solution = theta[0] + np.sum(np.matmul(theta[1: ], X))\n",
    "    \n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】最急降下法\n",
    "\n",
    "最急降下法により学習させる実装を行なう。\n",
    "\n",
    "以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにする。\n",
    "\n",
    "$\\begin{align}\n",
    "\\theta_j := \\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}[(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}]\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\\theta_j\\end{align}$：\n",
    "\n",
    "$\\begin{align}\\alpha\\end{align}$：学習率\n",
    "\n",
    "$\\begin{align}i\\end{align}$：サンプルのインデックス\n",
    "\n",
    "$\\begin{align}j\\end{align}$：特徴量のインデックス\n",
    "\n",
    "$\\begin{align}m\\end{align}$：サンプルの最大インデックス値（繰り返し回数の最大値）\n",
    "\n",
    "$h_\\theta(x^{(i)})$：_linear_hypothesis\n",
    "\n",
    "$\\begin{align}y^{(i)}\\end{align}$：y_train\n",
    "\n",
    "$\\begin{align}x_j^{(i)}\\end{align}$：X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【目的】\n",
    "\n",
    "* ひな形_gradient_descent（勾配降下）を用いて、最急降下法による機械学習が行えるように関数を完成させる。\n",
    "\n",
    "### 【考察】\n",
    "\n",
    "* 最急降下法とは、接線の傾き（$\\theta$）をゼロに近づくようにxの値を更新していき最適解に収束させる方法。\n",
    "* := の意味は「左辺を右辺で定義（代入）する」\n",
    "* 偏微分：特定の文字以外を定数とみなして微分したものを偏微分（偏導関数）と言います。\n",
    "    * 微分：ある関数の任意の点における傾き（$\\theta$）を導く式「導関数」を求めること。\n",
    "    * 傾き（$\\theta$）を求めるには2点間の変化の割合を求めること。\n",
    "        * $変化の割合=\\frac{yの増加量}{xの増加量}$\n",
    "        \n",
    "\n",
    "最急降下法のアルゴリズム\n",
    "1. 対象とする関数を$(h_\\theta(x^{(i)})$とし、関数$(h_\\theta(x^{(i)})$の引数のベクトルをX\n",
    "2. $h_\\theta(x^{(i)})-y^{(i)}$が偏差となる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(self, X, error):\n",
    "    \"\"\"\n",
    "    fitメソッドで呼び出された際に最急降下法による学習を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: class関数を引用する。\n",
    "    \n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "    \n",
    "    error : \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果    \n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # h_thetaとyはnumpy.ndarrayであること\n",
    "    # inside_sigma = np.multiply((h_theta - y_train), X_train)\n",
    "    \n",
    "    # theta = theta - lr * (1/m) * np.sum(inside_sigma, axis=0)\n",
    "    # or\n",
    "    theta -= (sum(_linear_hypothesis(X, theta)-y)/m) * X\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
