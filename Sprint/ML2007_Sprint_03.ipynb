{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint_03 機械学習スクラッチ　線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:06:36.635465Z",
     "start_time": "2020-11-11T09:06:36.627487Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.coef = None\n",
    "        \n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        loss : numpy.float\n",
    "            訓練用データから算出した損失関数\n",
    "        val_loss : numpy.float\n",
    "            検証用データから算出した損失関数\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        self.coef_ = self._gradient_descent(self, X)\n",
    "        \n",
    "        self.loss = self._cost_function(hypothesis , y)\n",
    "        \n",
    "        self.val_loss = self._cost_function(X_pred, y_val)\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "\n",
    "    def _gradient_descent(self, X, y):\n",
    "        \"\"\"\n",
    "        fitメソッドで呼び出された際に最急降下法による学習を行う。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        self: class関数を引用する。\n",
    "\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "\n",
    "        error : \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果    \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # h_thetaとyはnumpy.ndarrayであること\n",
    "        # inside_sigma = np.multiply((h_theta - y_train), X_train)\n",
    "\n",
    "        # ceof = coef - lr * (1/m) * np.sum(inside_sigma, axis=0)\n",
    "        # or\n",
    "        # coef -= (sum(_linear_hypothesis(X, coef)-y)/len(X)) * X\n",
    "\n",
    "        self.coef_ = self.coef_ - self.lr(1/len(X)) * np.matmul((_linear_hypothesis(X, coef_)-y), X)\n",
    "\n",
    "        return self.coef_\n",
    "    def _linear_hypothesis(self, X, _coef):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          訓練データ\n",
    "\n",
    "        theta : 次の形のndarray, shape (n_samples, )\n",
    "         パラメータ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        solution = _coef[0] + np.sum(np.matmul(_coef[1: ], X))\n",
    "    \n",
    "        return solution\n",
    "    \n",
    "    def _cost_function(y_pred, y):\n",
    "        \"\"\"\n",
    "        目的関数（損失関数）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        loss : numpy.float\n",
    "          訓練用データと検証用データから算出した損失関数に用いられる。\n",
    "        \"\"\"\n",
    "\n",
    "        loss = np.square(np.subtract(y_pred, y)) / (2 * len(y))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        return _linear_hypothesis(self, X, self.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題1】仮定関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "以下の数式で表される線形回帰の仮定関数を実装せよ。\n",
    "\n",
    "$\\begin{align}\n",
    "h_\\theta(x) = \\theta_0x_0 + \\theta_1x_1+...+\\theta_jx_j+...+\\theta_nx_n (x_0=1)\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}(x_0=1)\\end{align}$のため、実際の式はこうなる。\n",
    "\n",
    "$\\begin{align}\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1x_1+...+\\theta_jx_j+...+\\theta_nx_n (x_0=1)\n",
    "\\end{align}$\n",
    "### 【目的】\n",
    "\n",
    "* 上記の重回帰式を仮定する関数を作成する。\n",
    "\n",
    "### 【考察】\n",
    "\n",
    "* $\\begin{align}\\theta\\end{align}$ は直線の傾き（coefficients）を制御している。\n",
    "* $\\begin{align}x_0 = 1\\end{align}$ のため、切片は1である。\n",
    "* 行列 $\\begin{align}\\theta\\end{align}$ と行列 $\\begin{align}x_n\\end{align}$ の内積（np.dot or np.matmul）を算出する関数を作成する。\n",
    "* 内積を算出するため、引数xの行数分の配列数thetaをnp.randomを用いて算出する。\n",
    "\n",
    "### 【工程順序】\n",
    "1. np.random（0-10の範囲）を用いて、xの行数分の配列数thetaのarrayを構築\n",
    "2. x_train（ここでは引数x）を用いて$\\begin{align}h_\\theta\\end{align}$(x)を求める。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:59:09.794928Z",
     "start_time": "2020-11-11T08:59:09.791936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:01:02.232116Z",
     "start_time": "2020-11-11T09:01:02.229124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _linear_hypothesis(self, X, coef_):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    \n",
    "    theta : 次の形のndarray, shape (n_samples, )\n",
    "    　パラメータ\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    Process\n",
    "    -------    \n",
    "      1. theta[0]はそのままにして、残りの行数分Xと配列数分y（ここではtheta）の積の和を求める。\n",
    "      2. Xとthetaの行列の積はnp.matmulを使う。\n",
    "      3. np.sumで積の総和を求める。\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    solution = coef_[0] + np.sum(np.matmul(coef_[1: ], X))\n",
    "    # solution = theta[0] + np.prod(theta[1: ], X)\n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題2】最急降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "最急降下法により学習させる実装を行なう。\n",
    "\n",
    "以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにする。\n",
    "\n",
    "$\\begin{align}\n",
    "\\theta_j := \\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}[(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}]\n",
    "\\end{align}$\n",
    "\n",
    "ベクトル形式で表すとこうなる。\n",
    "\n",
    "$\\begin{align}\n",
    "\\theta := \\theta-\\alpha\\frac{1}{m}[(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}]\n",
    "\\end{align}$\n",
    "\n",
    "偏差を求める式がこの部分\n",
    "\n",
    "仮定した傾きから得た値yを実際のyとの差を求める部分である。\n",
    "\n",
    "$\\begin{align}\n",
    "(h_\\theta(x^{(i)})-y^{(i)})\n",
    "\\end{align}$\n",
    "\n",
    "-----\n",
    "\n",
    "$\\begin{align}:=\\end{align}$：左辺を右辺によって定義する。\n",
    "\n",
    "$\\begin{align}\\theta_j\\end{align}$：傾き \n",
    "```python \n",
    "_coef\n",
    "```\n",
    "$\\begin{align}\\alpha\\end{align}$：学習率\n",
    "```python \n",
    "self.lr\n",
    "```\n",
    "$\\begin{align}i\\end{align}$：サンプル（要素）のインデックス位置\n",
    "\n",
    "$\\begin{align}j\\end{align}$：特徴量のインデックス位置\n",
    "\n",
    "$\\begin{align}m\\end{align}$：サンプル（要素）の最大インデックス値（繰り返し回数の最大値）\n",
    "```python \n",
    "len(X)\n",
    "```\n",
    "$h_\\theta(x^{(i)})$：_linear_hypothesis\n",
    "\n",
    "$\\begin{align}y^{(i)}\\end{align}$：y_train\n",
    "\n",
    "$\\begin{align}x_j^{(i)}\\end{align}$：X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 【目的】\n",
    "\n",
    "* ひな形_gradient_descent（勾配降下）を用いて、最急降下法による機械学習が行えるように関数を完成させる。\n",
    "\n",
    "### 【考察】\n",
    "\n",
    "* 最急降下法とは、接線の傾き（$\\theta$）をゼロに近づくようにxの値を更新していき最適解に収束させる方法。\n",
    "* := の意味は「左辺を右辺で定義（代入）する」\n",
    "* 偏微分：特定の文字以外を定数とみなして微分したものを偏微分（偏導関数）と言います。\n",
    "    * 微分：ある関数の任意の点における傾き（$\\theta$）を導く式「導関数」を求めること。\n",
    "    * 傾き（$\\theta$）を求めるには2点間の変化の割合を求めること。\n",
    "        * $変化の割合=\\frac{yの増加量}{xの増加量}$\n",
    "\n",
    "最急降下法のアルゴリズム\n",
    "1. 対象とする関数を$(h_\\theta(x^{(i)})$とし、関数$(h_\\theta(x^{(i)})$の引数となるのがベクトルX\n",
    "2. $h_\\theta(x^{(i)})-y^{(i)}$が偏差となる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:02:44.773780Z",
     "start_time": "2020-11-11T09:02:44.769791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _gradient_descent(self, X, y):\n",
    "    \"\"\"\n",
    "    fitメソッドで呼び出された際に最急降下法による学習を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: class関数を引用する。\n",
    "    \n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "    \n",
    "    error : \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果    \n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # h_thetaとyはnumpy.ndarrayであること\n",
    "    # inside_sigma = np.multiply((h_theta - y_train), X_train)\n",
    "    \n",
    "    # ceof = coef - lr * (1/m) * np.sum(inside_sigma, axis=0)\n",
    "    # or\n",
    "    # coef -= (sum(_linear_hypothesis(X, coef)-y)/len(X)) * X\n",
    "    \n",
    "    self.coef_ = self.coef_ - self.lr(1/len(X)) * np.matmul((_linear_hypothesis(X, coef_)-y), X)\n",
    "    \n",
    "    return self.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題3】推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* 推定する仕組みを実装せよ。\n",
    "* ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えること。\n",
    "* 仮定関数 $h_\\theta(x)$ (_linear_hypothesis)の出力が推定結果とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:00:11.968519Z",
     "start_time": "2020-11-11T08:00:11.965527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "    return _linear_hypothesis(self, X, _coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* 線形回帰の指標値として用いられる平均二乗誤差（mean square error, MSE）の関数を作成せよ。\n",
    "* 平均二乗誤差は以下の数式で表される。\n",
    "\n",
    "$\\begin{align}\n",
    "L(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\n",
    "\\end{align}$\n",
    "\n",
    "$m$ : 入力されるデータの数 \n",
    "```python\n",
    "len(y)\n",
    "```\n",
    "$h_\\theta(x)$ : 仮定関数\n",
    "```pythonn\n",
    "y_pred\n",
    "```\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値\n",
    "```python\n",
    "y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:24:11.257238Z",
     "start_time": "2020-11-11T08:24:11.254246Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    \n",
    "    mse = np.square(np.subtract(y_pred, y)).mean()\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 【問題5】目的関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* 以下の数式で表される線形回帰の**目的関数（損失関数）**を実装せよ。\n",
    "* そして、これをself.loss, self.val_lossに記録すること。\n",
    "\n",
    "$\\begin{align}\n",
    "J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^2\n",
    "\\end{align}$\n",
    "\n",
    "$m$ : 入力されるデータの数\n",
    "```python\n",
    "len(y)\n",
    "```\n",
    "$h_\\theta(X)$ : 仮定関数\n",
    "```python\n",
    "y_pred\n",
    "```\n",
    "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "$y^{(i)}$ : i番目のサンプルの正解値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T08:52:12.749173Z",
     "start_time": "2020-11-11T08:52:12.746180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _cost_function(y_pred, y):\n",
    "    \"\"\"\n",
    "    目的関数（損失関数）\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    loss : numpy.float\n",
    "      訓練用データと検証用データから算出した損失関数に用いられる。\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = np.square(np.subtract(y_pred, y)) / (2 * len(y))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* House Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なうこと。\n",
    "* scikit-learnによる実装と比べ、正しく動いているかを確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-11T09:11:05.578941Z",
     "start_time": "2020-11-11T09:11:05.372494Z"
    }
   },
   "outputs": [],
   "source": [
    "# File system manangement\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "house_df = pd.read_csv('../Data/house_prices_train.csv')\n",
    "\n",
    "# 目的変数\n",
    "y_house = np.array(house_df.loc[:, ['SalePrice']])\n",
    "\n",
    "# 説明変数\n",
    "X_house = np.array(house_df.loc[:, ['GrLivArea', 'YearBuilt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.12 Todo\n",
    "1. Scikit-learnの線形回帰を実装\n",
    "2. 自作の線形回帰を実装・回す。\n",
    "3. 上記の２モデルを比較検証\n",
    "4. アドバンス問題を挑戦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
