{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【考察】\n",
    "\n",
    "* どう決定木は作られていくか。\n",
    "* 以下の条件次第で、木の構成は変わる。\n",
    "    * 学習方法\n",
    "    * ハイパーパラメータ\n",
    "    * 訓練データ\n",
    "\n",
    "* 今回の決定木は量的変数のみに特化する。\n",
    "    * カテゴリ変数には「0と1」で代用する。\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    深さ1の決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】不純度を求める関数（CART式）\n",
    "\n",
    "### ノードのジニ不純度を計算する関数を作成してください\n",
    "\n",
    "* ジニ不純度とは、そのノードでのサンプルのクラスの異なりが同程度存在する確率。\n",
    "    * 確率が高いとノード内のサンプルが全て、異なるクラスに属している。\n",
    "        * データが半々なのは悪い分類\n",
    "    * 確率が低いとノード内のサンプルが全て、同じクラスに属している。\n",
    "    * ベルヌーイ分布における、全てのクラスの分散の和に相当する。\n",
    "* ノード内の不純度を最大限減らす（ジニ不純度が低い）素性と閾値の組を選ぶために、ジニ不純度を用いる。\n",
    "* 不純度が最も低ければジニ不純度の値は0、不純度が高くなればなるほどジニ不純度の値が1に漸近する。（[参照先url](https://qiita.com/3000manJPY/items/ef7495960f472ec14377)）\n",
    "* 最終的に情報利得Δgainで算出する。\n",
    "    * 利得が高い特徴と閾値ほど、不純度を最大限減らせる。\n",
    "    \n",
    "\n",
    "\n",
    "1. ジニ係数を算出する関数を構築する。\n",
    "2. ジニ係数を用い、情報利得を算出する関数を構築する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coef(*args):\n",
    "    \"\"\"\"\"\n",
    "    ジニ係数を算出する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *args : int\n",
    "        根ノード内の各特徴量毎のサンプル数（値）を渡す。\n",
    "        \n",
    "    return\n",
    "    ----------\n",
    "    ジニ係数\n",
    "    \"\"\"\"\"\n",
    "    sample_all = sum(args)\n",
    "    gini_coef_answer = 0\n",
    "    for i in range(len(args)):\n",
    "        gini_coef_answer += np.power(args[i]/sample_all, 2)\n",
    "    return 1 - gini_coef_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例題1のジニ不純度: 0.5\n",
      "\n",
      "例題2のジニ不純度: 0.67\n",
      "\n",
      "例題3のジニ不純度: 0.48\n",
      "\n",
      "例題4のジニ不純度: 0.0\n"
     ]
    }
   ],
   "source": [
    "# クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500\n",
    "print(f'例題1のジニ不純度: {gini_coef(15, 15)}')\n",
    "print()\n",
    "# クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667\n",
    "print(f'例題2のジニ不純度: {gini_coef(15, 15, 15) :.2f}')\n",
    "print()\n",
    "# クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480\n",
    "print(f'例題3のジニ不純度: {gini_coef(18, 12)}')\n",
    "print()\n",
    "# クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000\n",
    "print(f'例題4のジニ不純度: {gini_coef(30, 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】情報利得を求める関数\n",
    "\n",
    "* 問題1で算出した確率はジニ不純度（ジニ係数）$I(t)$をroot_node $I(p)$として用いる。\n",
    "* 左右各ノードのサンプル数を引数として情報利得を算出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left_node_1, left_node_2, right_node_1, right_node_2):\n",
    "    \"\"\"\"\"\n",
    "    情報利得を算出する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    left_node_1 : int\n",
    "        左ノード内の第1特徴量のサンプル数（値）を渡す。\n",
    "    left_node_2 : int\n",
    "        左ノード内の第2特徴量のサンプル数（値）を渡す。\n",
    "    right_node_1 : int\n",
    "        右ノード内の第1特徴量のサンプル数（値）を渡す。\n",
    "    right_node_2 : int\n",
    "        右ノード内の第2特徴量のサンプル数（値）を渡す。\n",
    "        \n",
    "    return\n",
    "    ----------\n",
    "    gain : float\n",
    "        情報利得\n",
    "    \"\"\"\"\"    \n",
    "    sample_all_list = [left_node_1, left_node_2, right_node_1, right_node_2] # パラメータのリスト化\n",
    "    sample_all = sum(sample_all_list) # 全サンプルの総和\n",
    "    \n",
    "    left_all = np.add(left_node_1, left_node_2) # 左分岐の総和\n",
    "    # print(f'left_all: {left_all}')\n",
    "    right_all = np.add(right_node_1, right_node_2) # 右分岐の総和\n",
    "    # print(f'right_all: {right_all}')\n",
    "    root_node = [left_node_1 + right_node_1, left_node_2 + right_node_2] # 根ノードの左右総和数をリスト化\n",
    "    # print(f'root_node: {root_node}')\n",
    "    \n",
    "    gini_coef_answer = 0 \n",
    "    for i in range(len(root_node)):\n",
    "        gini_coef_answer += np.power(root_node[i]/sample_all, 2)\n",
    "    gini_coef = 1 - gini_coef_answer # ジニ係数\n",
    "    # print(f'gini_coef: {gini_coef}')\n",
    "    \n",
    "    left_node_coef = 1 - (np.power(left_node_1/left_all, 2) + np.power(left_node_2/left_all, 2)) # 左ノードのジニ係数\n",
    "    # print(f'left_node_coef: {left_node_coef}')\n",
    "    right_node_coef = 1 - (np.power(right_node_1/right_all, 2) + np.power(right_node_2/right_all, 2)) # 右ノードのジニ係数\n",
    "    # print(f'right_node_coef: {right_node_coef}')\n",
    "    gain = gini_coef - ((left_all/sample_all) * left_node_coef) - ((right_all/sample_all) * right_node_coef) # 情報利得の算出\n",
    "    \n",
    "    # print(f'左辺: {(left_all/sample_all) * left_node_coef}')\n",
    "    # print(f'右辺: {(right_all/sample_all) * right_node_coef}')\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例題の情報利得：0.143\n",
      "スクラッチ関数の利得：0.143\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# 左ノードクラス1:サンプル数10, 左ノードクラス2:サンプル数30, 右ノードクラス1:サンプル数20, 右ノードクラス2:サンプル数5 → 情報利得0.143\n",
    "answer = info_gain(10, 30, 20, 5)\n",
    "print('例題の情報利得：0.143')\n",
    "print(f'スクラッチ関数の利得：{answer:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習\n",
    "\n",
    "1. 全サンプルの情報利得を算出する。\n",
    "\n",
    "    1. 説明変数Xから、行列内の要素を一つ抽出する。\n",
    "    2. 抽出した要素を閾値として、全ての説明変数を葉ノードに振り分ける。\n",
    "        * 閾値以下：左\n",
    "        * 閾値以上：右\n",
    "    3. 左右の葉ノード内も目的変数yの0, 1の個数を返す。\n",
    "        * 情報利得算出に必要なのはラベル別の個数！\n",
    "            * 葉ノードのラベル別個数\n",
    "                * left_node_1\n",
    "                * left_node_2\n",
    "                * right_node_1\n",
    "                * right_node_2\n",
    "    4. 問題2の関数を用いて、情報利得を算出する。\n",
    "    5. 算出した情報利得を新しい行列内に追記する。\n",
    "    6. 最初に戻り、次のインデックスを抽出する。（繰り返す）\n",
    "    7. 全てのインデックスを基に算出した情報利得を代入した行列を完成させる。\n",
    "2. 最大値の情報利得を抽出する。\n",
    "    1. numpyの特性上、情報利得を代入した行列内の各列毎の最大値を抽出する。\n",
    "    2. 各列毎の最大値の中で、最も高い数値の要素とインデックスを抽出する。\n",
    "    3. 抽出した要素とインデックスをインスタンス化させて、次の推定に活用する。\n",
    "    \n",
    "    \n",
    "    \n",
    "    閾値をとりあえず設定する。\n",
    "    データを2領域に分割する（閾値を基に）\n",
    "    分割した領域の中でラベル事の個数を求める。\n",
    "    利得を求める。\n",
    "    以降、繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 3,  4],\n",
       "       [ 5,  6],\n",
       "       [ 7,  8],\n",
       "       [ 9, 10]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "X = np.array([[1, 2],[3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 1, 0, 1]).reshape(5, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "インデックス0の位置：[0, 3] \n",
      "インデックス1の位置：[1, 2, 4]\n",
      "インデックス0の個数：2\n",
      "インデックス1の個数：3\n"
     ]
    }
   ],
   "source": [
    "# 目的変数yの1次元行列の内、0のインデックス、1のインデックスを返す。\n",
    "y_count_0 = np.where(y == 0)[0].tolist()\n",
    "y_count_1 = np.where(y == 1)[0].tolist()\n",
    "print(f'インデックス0の位置：{y_count_0} \\nインデックス1の位置：{y_count_1}')\n",
    "\n",
    "# 返されたインデックスが、説明変数Xの行数になる。\n",
    "# 0と1の個数も同時に算出する。（np.uniqueのreturn_countsを使う。）\n",
    "counts_0_1 = np.unique(y, return_counts=True)[1]\n",
    "print(f'インデックス0の個数：{counts_0_1[0]}\\nインデックス1の個数：{counts_0_1[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値から葉ノードへの分別\n",
    "# 0列目が4の場合とする。\n",
    "# 0列目が4以下の場合はleft、4以上の場合はright\n",
    "\n",
    "threshold = X[1, 1]\n",
    "terminal_node_left_index = list(zip(*np.where(X < threshold)))\n",
    "terminal_node_right_index = list(zip(*np.where(X > threshold)))\n",
    "# terminal_node_left_array = X[]\n",
    "# print(f'左の葉ノード（0列目が3以下）に分別された行列：')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# 0列目の要素\n",
    "print(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0列目が閾値以下（左葉ノード）に該当する行数：[(0,), (1,)]\n",
      "1列目が閾値以下（左葉ノード）に該当する行数：[(0,)]\n",
      "0列目が閾値以上（右葉ノード）に該当する行数：[(2,), (3,), (4,)]\n",
      "1列目が閾値以上（右葉ノード）に該当する行数：[(2,), (3,), (4,)]\n"
     ]
    }
   ],
   "source": [
    "# 0列目が閾値以下に該当する行数\n",
    "threshold = 4\n",
    "\n",
    "terminal_node_left_row_0 = list(zip(*np.where(X[:, 0] < threshold)))\n",
    "print(f'0列目が閾値以下（左葉ノード）に該当する行数：{terminal_node_left_row_0}')\n",
    "\n",
    "# 1列目が閾値以下に該当する行数\n",
    "terminal_node_left_row_1 = list(zip(*np.where(X[:, 1] < threshold)))\n",
    "print(f'1列目が閾値以下（左葉ノード）に該当する行数：{terminal_node_left_row_1}')\n",
    "\n",
    "# 0列目が閾値以上に該当する行数\n",
    "terminal_node_right_row_0 = list(zip(*np.where(X[:, 0] > threshold)))\n",
    "print(f'0列目が閾値以上（右葉ノード）に該当する行数：{terminal_node_right_row_0}')\n",
    "\n",
    "# 1列目が閾値以上に該当する行数\n",
    "terminal_node_right_row_1 = list(zip(*np.where(X[:, 1] > threshold)))\n",
    "print(f'1列目が閾値以上（右葉ノード）に該当する行数：{terminal_node_right_row_0}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0列目が閾値3の場合\n",
    "# 葉ノードのラベル別個数\n",
    "# terminal_node_left_row_0の返り値は行数\n",
    "# インデックス0と1の位置が代入されたリストと照合して、left_node_1とleft_node_2に分別する。\n",
    "\n",
    "\n",
    "left_node_1 = len(terminal_node_left_row_0)\n",
    "\n",
    "\n",
    "#left_node_2 = len()\n",
    "#right_node_1 =\n",
    "#right_node_2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    \"\"\"\n",
    "    決定木分類器を学習する\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "    \"\"\"\n",
    "  \n",
    "    # 1_A\n",
    "    threshold = X[0, 0]\n",
    "    terminal_node_left = np.where(X < threshold)\n",
    "    terminal_node_right = \n",
    "    root_node_0 = left_node_1 + right_node_1\n",
    "    root_node_1 = left_node_2 + right_node_2\n",
    "    \n",
    "    root_node = [root_node_0, root_node_1] # 根ノードの左右総和数をリスト化\n",
    "    # print(f'root_node: {root_node}')\n",
    "    \n",
    "    \n",
    "    if self.verbose:\n",
    "        #verboseをTrueにした際は学習過程を出力\n",
    "        print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47337278106508873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node = [40, 25]\n",
    "sample_all = sum(root_node)\n",
    "gini_coef_answer = 0 \n",
    "\n",
    "for i in range(len(root_node)):\n",
    "    gini_coef_answer += np.power(root_node[i]/sample_all, 2)\n",
    "gini_coef = 1 - gini_coef_answer # ジニ係数\n",
    "\n",
    "gini_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "X = np.array([[1, 2],[3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 1, 0, 1]).reshape(5, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  0],\n",
       "       [ 3,  4,  1],\n",
       "       [ 5,  6,  1],\n",
       "       [ 7,  8,  0],\n",
       "       [ 9, 10,  1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node_array = np.append(X, y, axis=1)\n",
    "root_node_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node_0 = np.any(root_node_array[:, 2:3] == 0, axis=1)\n",
    "root_node_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  0],\n",
       "       [ 3,  4,  1],\n",
       "       [ 5,  6,  1],\n",
       "       [ 7,  8,  0],\n",
       "       [ 9, 10,  1]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
