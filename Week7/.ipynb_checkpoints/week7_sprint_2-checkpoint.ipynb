{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【考察】\n",
    "\n",
    "* どう決定木は作られていくか。\n",
    "* 以下の条件次第で、木の構成は変わる。\n",
    "    * 学習方法\n",
    "    * ハイパーパラメータ\n",
    "    * 訓練データ\n",
    "\n",
    "* 今回の決定木は量的変数のみに特化する。\n",
    "    * カテゴリ変数には「0と1」で代用する。\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDecesionTreeClassifierDepth1():\n",
    "    \"\"\"\n",
    "    深さ1の決定木分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        決定木分類器を学習する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        決定木分類器を使いラベルを推定する\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】不純度を求める関数（CART式）\n",
    "\n",
    "### ノードのジニ不純度を計算する関数を作成してください\n",
    "\n",
    "* ジニ不純度とは、そのノードでのサンプルのクラスの異なりが同程度存在する確率。\n",
    "    * 確率が高いとノード内のサンプルが全て、異なるクラスに属している。\n",
    "        * データが半々なのは悪い分類\n",
    "    * 確率が低いとノード内のサンプルが全て、同じクラスに属している。\n",
    "    * ベルヌーイ分布における、全てのクラスの分散の和に相当する。\n",
    "* ノード内の不純度を最大限減らす（ジニ不純度が低い）素性と閾値の組を選ぶために、ジニ不純度を用いる。\n",
    "* 不純度が最も低ければジニ不純度の値は0、不純度が高くなればなるほどジニ不純度の値が1に漸近する。（[参照先url](https://qiita.com/3000manJPY/items/ef7495960f472ec14377)）\n",
    "* 最終的に情報利得Δgainで算出する。\n",
    "    * 利得が高い特徴と閾値ほど、不純度を最大限減らせる。\n",
    "    \n",
    "\n",
    "\n",
    "1. ジニ係数を算出する関数を構築する。\n",
    "2. ジニ係数を用い、情報利得を算出する関数を構築する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coef(*args):\n",
    "    \"\"\"\"\"\n",
    "    ジニ係数を算出する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    *args : int\n",
    "        根ノード内の各特徴量毎のサンプル数（値）を渡す。\n",
    "        \n",
    "    return\n",
    "    ----------\n",
    "    ジニ係数\n",
    "    \"\"\"\"\"\n",
    "    sample_all = sum(args)\n",
    "    gini_coef_answer = 0\n",
    "    for i in range(len(args)):\n",
    "        gini_coef_answer += np.power(args[i]/sample_all, 2)\n",
    "    return 1 - gini_coef_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例題1のジニ不純度: 0.5\n",
      "\n",
      "例題2のジニ不純度: 0.67\n",
      "\n",
      "例題3のジニ不純度: 0.48\n",
      "\n",
      "例題4のジニ不純度: 0.0\n"
     ]
    }
   ],
   "source": [
    "# クラス1:サンプル数15, クラス2:サンプル数15 → ジニ不純度0.500\n",
    "print(f'例題1のジニ不純度: {gini_coef(15, 15)}')\n",
    "print()\n",
    "# クラス1:サンプル数15, クラス2:サンプル数15, クラス3:サンプル数15 → ジニ不純度0.667\n",
    "print(f'例題2のジニ不純度: {gini_coef(15, 15, 15) :.2f}')\n",
    "print()\n",
    "# クラス1:サンプル数18, クラス2:サンプル数12 → ジニ不純度0.480\n",
    "print(f'例題3のジニ不純度: {gini_coef(18, 12)}')\n",
    "print()\n",
    "# クラス1:サンプル数30, クラス2:サンプル数0 → ジニ不純度0.000\n",
    "print(f'例題4のジニ不純度: {gini_coef(30, 0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】情報利得を求める関数\n",
    "\n",
    "* 問題1で算出した確率はジニ不純度（ジニ係数）$I(t)$をroot_node $I(p)$として用いる。\n",
    "* 左右各ノードのサンプル数を引数として情報利得を算出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left_node_0, left_node_1, right_node_0, right_node_1):\n",
    "    \"\"\"\"\"\n",
    "    情報利得を算出する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    left_node_0 : int\n",
    "        左ノード内の第1特徴量のサンプル数（値）を渡す。\n",
    "    left_node_1 : int\n",
    "        左ノード内の第2特徴量のサンプル数（値）を渡す。\n",
    "    right_node_0 : int\n",
    "        右ノード内の第1特徴量のサンプル数（値）を渡す。\n",
    "    right_node_1 : int\n",
    "        右ノード内の第2特徴量のサンプル数（値）を渡す。\n",
    "        \n",
    "    return\n",
    "    ----------\n",
    "    gain : float\n",
    "        情報利得\n",
    "    \"\"\"\"\"    \n",
    "    sample_all_list = [left_node_0, left_node_1, right_node_0, right_node_1] # パラメータのリスト化\n",
    "    sample_all = sum(sample_all_list) # 全サンプルの総和\n",
    "    \n",
    "    left_all = np.add(left_node_0, left_node_1) # 左分岐の総和\n",
    "    # print(f'left_all: {left_all}')\n",
    "    right_all = np.add(right_node_0, right_node_1) # 右分岐の総和\n",
    "    # print(f'right_all: {right_all}')\n",
    "    root_node = [left_node_0 + right_node_0, left_node_1 + right_node_1] # 根ノードの左右総和数をリスト化\n",
    "    # print(f'root_node: {root_node}')\n",
    "    \n",
    "    gini_coef_answer = 0 \n",
    "    for i in range(len(root_node)):\n",
    "        gini_coef_answer += np.power(root_node[i]/sample_all, 2)\n",
    "    gini_coef = 1 - gini_coef_answer # ジニ係数\n",
    "    # print(f'gini_coef: {gini_coef}')\n",
    "    \n",
    "    left_node_coef = 1 - (np.power(left_node_0/left_all, 2) + np.power(left_node_1/left_all, 2)) # 左ノードのジニ係数\n",
    "    # print(f'left_node_coef: {left_node_coef}')\n",
    "    right_node_coef = 1 - (np.power(right_node_0/right_all, 2) + np.power(right_node_1/right_all, 2)) # 右ノードのジニ係数\n",
    "    # print(f'right_node_coef: {right_node_coef}')\n",
    "    gain = gini_coef - ((left_all/sample_all) * left_node_coef) - ((right_all/sample_all) * right_node_coef) # 情報利得の算出\n",
    "    \n",
    "    # print(f'左辺: {(left_all/sample_all) * left_node_coef}')\n",
    "    # print(f'右辺: {(right_all/sample_all) * right_node_coef}')\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "例題の情報利得：0.143\n",
      "スクラッチ関数の利得：0.143\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# 左ノードクラス1:サンプル数10, 左ノードクラス2:サンプル数30, 右ノードクラス1:サンプル数20, 右ノードクラス2:サンプル数5 → 情報利得0.143\n",
    "answer = info_gain(10, 30, 20, 5)\n",
    "print('例題の情報利得：0.143')\n",
    "print(f'スクラッチ関数の利得：{answer:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】学習\n",
    "\n",
    "全サンプルの情報利得を算出する。\n",
    "\n",
    "1. 説明変数Xから、行列内の要素を一つ抽出する。\n",
    "2. 抽出した要素を閾値として、全ての説明変数を葉ノードに振り分ける。\n",
    "    * 閾値以下：左\n",
    "    * 閾値以上：右\n",
    "3. 左右の葉ノード内も目的変数yの0, 1の個数を返す。\n",
    "    * 情報利得算出に必要なのはラベル別の個数！\n",
    "        * 葉ノードのラベル別個数\n",
    "            * left_node_1\n",
    "            * left_node_2\n",
    "            * right_node_1\n",
    "            * right_node_2\n",
    "4. 問題2の関数を用いて、情報利得を算出する。\n",
    "5. 算出した情報利得を新しい行列内に追記する。\n",
    "6. 最初に戻り、次のインデックスを抽出する。（繰り返す）\n",
    "7. 全てのインデックスを基に算出した情報利得を代入した行列を完成させる。\n",
    "8. 最大値の情報利得を抽出する。\n",
    "    1. 情報利得を代入した行列内の最大値を抽出する。\n",
    "    2. 抽出した要素とインデックスをインスタンス化させて、次の推定に活用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 3,  4],\n",
       "       [ 5,  6],\n",
       "       [ 7,  8],\n",
       "       [ 9, 10]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "X = np.array([[1, 2],[3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 1, 1, 0, 1])\n",
    "# y = [0, 1, 1, 0, 1]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 学習データ内の特徴量別の行番号、個数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "インデックス0の行番号：[0, 3] \n",
      "インデックス1の行番号：[1, 2, 4]\n",
      "インデックス0の個数：2\n",
      "インデックス1の個数：3\n"
     ]
    }
   ],
   "source": [
    "# 目的変数yの1次元行列の内、0のインデックス、1のインデックスを返す。\n",
    "y_count_0 = np.where(y == 0)[0].tolist()\n",
    "y_count_1 = np.where(y == 1)[0].tolist()\n",
    "print(f'インデックス0の行番号：{y_count_0} \\nインデックス1の行番号：{y_count_1}')\n",
    "# 返されたインデックスが、説明変数Xの行数になる。\n",
    "\n",
    "# 0と1の個数も同時に算出する。（np.uniqueのreturn_countsを使う。）\n",
    "counts_0_1 = np.unique(y, return_counts=True)[1]\n",
    "print(f'インデックス0の個数：{counts_0_1[0]}\\nインデックス1の個数：{counts_0_1[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 閾値に基づいて、全サンプルを葉ノードへ振り分ける。（例：閾値 = 4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0列目が閾値以下（左葉ノード）に該当する行数：[(0,), (1,)]\n",
      "1列目が閾値以下（左葉ノード）に該当する行数：[(0,)]\n",
      "0列目が閾値以上（右葉ノード）に該当する行数：[(2,), (3,), (4,)]\n",
      "1列目が閾値以上（右葉ノード）に該当する行数：[(2,), (3,), (4,)]\n"
     ]
    }
   ],
   "source": [
    "threshold = 4\n",
    "\n",
    "# 0列目が閾値以下に該当する行数\n",
    "terminal_node_left_row_0 = list(zip(*np.where(X[:, 0] < threshold)))\n",
    "print(f'0列目が閾値以下（左葉ノード）に該当する行数：{terminal_node_left_row_0}')\n",
    "\n",
    "# 1列目が閾値以下に該当する行数\n",
    "terminal_node_left_row_1 = list(zip(*np.where(X[:, 1] < threshold)))\n",
    "print(f'1列目が閾値以下（左葉ノード）に該当する行数：{terminal_node_left_row_1}')\n",
    "\n",
    "# 0列目が閾値以上に該当する行数\n",
    "terminal_node_right_row_0 = list(zip(*np.where(X[:, 0] > threshold)))\n",
    "print(f'0列目が閾値以上（右葉ノード）に該当する行数：{terminal_node_right_row_0}')\n",
    "\n",
    "# 1列目が閾値以上に該当する行数\n",
    "terminal_node_right_row_1 = list(zip(*np.where(X[:, 1] > threshold)))\n",
    "print(f'1列目が閾値以上（右葉ノード）に該当する行数：{terminal_node_right_row_0}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 左右の葉ノードへ振り分けた後、各特徴量別の行番号を抽出（重複させないためunique関数を用いる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "左葉ノードに該当するXの行番号は：[0, 1]\n",
      "右葉ノードに該当するXの行番号は：[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "left_u = np.unique(np.append(terminal_node_left_row_0, terminal_node_left_row_1))\n",
    "right_u = np.unique(np.append(terminal_node_right_row_0, terminal_node_right_row_1))\n",
    "print(f'左葉ノードに該当するXの行番号は：{left_u.tolist()}\\n右葉ノードに該当するXの行番号は：{right_u.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. 左右の葉ノードの各特徴量ごとにサンプル数を振り分ける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "左葉ノードのラベル0に該当するサンプル個数は：1\n",
      "左葉ノードのラベル1に該当するサンプル個数は：1\n",
      "右葉ノードのラベル0に該当するサンプル個数は：1\n",
      "右葉ノードのラベル1に該当するサンプル個数は：2\n"
     ]
    }
   ],
   "source": [
    "left_node_0, left_node_1, right_node_0, right_node_1 = 0, 0, 0, 0\n",
    "for i in left_u:\n",
    "    if y[i] == 0:\n",
    "        left_node_0 += 1\n",
    "    elif y[i] == 1:\n",
    "        left_node_1 += 1\n",
    "    else:\n",
    "        pass\n",
    "for j in right_u:\n",
    "    if y[j] == 0:\n",
    "        right_node_0 += 1\n",
    "    elif y[j] == 1:\n",
    "        right_node_1 += 1\n",
    "    else:\n",
    "        pass\n",
    "print(f'左葉ノードのラベル0に該当するサンプル個数は：{left_node_0}\\n左葉ノードのラベル1に該当するサンプル個数は：{left_node_1}')\n",
    "print(f'右葉ノードのラベル0に該当するサンプル個数は：{right_node_0}\\n右葉ノードのラベル1に該当するサンプル個数は：{right_node_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-5. 問題2の関数を用いて、閾値=4の情報利得を算出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "閾値：4\n",
      "情報利得：0.01\n"
     ]
    }
   ],
   "source": [
    "gain = info_gain(left_node_0, left_node_1, right_node_0, right_node_1)\n",
    "print(f'閾値：{threshold}\\n情報利得：{gain:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-6. 算出した情報利得を閾値として抽出した要素の元の位置と同じ場所に、同サイズの新規行列に代入する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   ],\n",
       "       [0.   , 0.013],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 算出した情報利得をXと同じサイズに行列化\n",
    "# 空の行列を作成する。\n",
    "\n",
    "X_gain = np.zeros(X.shape)\n",
    "\n",
    "# for文を用いるため、インデックスはiとjを用いるが、今回は例として閾値=4がある(1, 1)を使う。\n",
    "X_gain[1, 1] = gain\n",
    "X_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-7. 完成した行列内からnanを除外した、最大値とその位置を算出する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gain = np.nanmax(X_gain)\n",
    "max_index = list(zip(*np.where(X_gain == max_gain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-8. 上記の一通りの流れを関数化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_array_of_gain(threshold):\n",
    "    \"\"\"\"\"\n",
    "    指定した閾値から、深度1に進めた後、info_gain関数を用いて情報利得を算出して、新規作成した行列に代入する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : int\n",
    "        閾値\n",
    "    return\n",
    "    ----------\n",
    "    gain : float\n",
    "        指定した閾値の情報利得\n",
    "    \"\"\"\"\"    \n",
    "    \n",
    "    # np.set_printoptions(precision=3)\n",
    "    terminal_node_left_row_0 = list(zip(*np.where(X[:, 0] < threshold)))\n",
    "    terminal_node_left_row_1 = list(zip(*np.where(X[:, 1] < threshold)))\n",
    "    terminal_node_right_row_0 = list(zip(*np.where(X[:, 0] > threshold)))\n",
    "    terminal_node_right_row_1 = list(zip(*np.where(X[:, 1] > threshold)))\n",
    "\n",
    "    left_u = np.unique(np.append(terminal_node_left_row_0, terminal_node_left_row_1))\n",
    "    right_u = np.unique(np.append(terminal_node_right_row_0, terminal_node_right_row_1))\n",
    "    \n",
    "    left_node_0, left_node_1, right_node_0, right_node_1 = 0, 0, 0, 0\n",
    "    for i in range(len(left_u)):\n",
    "        if y[i] == 0:\n",
    "            left_node_0 += 1\n",
    "        elif y[i] == 1:\n",
    "            left_node_1 += 1\n",
    "        else:\n",
    "            pass\n",
    "    for j in range(len(right_u)):\n",
    "        if y[j] == 0:\n",
    "            right_node_0 += 1\n",
    "        elif y[j] == 1:\n",
    "            right_node_1 += 1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    gain = info_gain(left_node_0, left_node_1, right_node_0, right_node_1)\n",
    "\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-9. 全特徴量毎の全サンプル数から閾値を決めて、上記の深度1の決定木から情報利得を算出する関数を組み込んだ関数を作成して、情報利得の最大値とその位置を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 閾値から葉ノードへの振り分ける。\n",
    "# 閾値は0列目からfor文で廻す。\n",
    "\n",
    "X_gain = np.zeros(X.shape)\n",
    "for i in range(X.shape[1]): # 各列毎\n",
    "    for j in range(X.shape[0]): # 各行毎\n",
    "        threshold = X[j, i]\n",
    "        # print(f'threshold: {threshold}')\n",
    "        gain = making_array_of_gain(threshold)\n",
    "        # print(f'gain: {gain} at {j, i}')\n",
    "        X_gain[j, i] = gain\n",
    "\n",
    "max_gain = np.nanmax(X_gain)\n",
    "max_index = list(zip(*np.where(X_gain == max_gain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-10. 雛型のfit関数へ組み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    \"\"\"\n",
    "    全特徴量の全サンプルの中から、最適な情報利得とその位置を算出する。\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        訓練データの特徴量\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "        訓練データの正解値\n",
    "    \"\"\"\n",
    "    \n",
    "    # 閾値は0列目からfor文で廻す。\n",
    "\n",
    "    X_gain = np.zeros(X.shape)\n",
    "    for i in range(X.shape[1]): # 各列毎\n",
    "        for j in range(X.shape[0]): # 各行毎\n",
    "            threshold = X[j, i]\n",
    "            # print(f'threshold: {threshold}')\n",
    "            gain = making_array_of_gain(threshold) # 情報利得を算出\n",
    "            # print(f'gain: {gain} at {j, i}')\n",
    "            X_gain[j, i] = gain\n",
    "\n",
    "    max_gain = np.nanmax(X_gain)\n",
    "    max_index = list(zip(*np.where(X_gain == max_gain)))\n",
    "    if self.verbose:\n",
    "        #verboseをTrueにした際は学習過程を出力\n",
    "        print()\n",
    "    \n",
    "    return max_gain, max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】推定\n",
    "\n",
    "推定する仕組みを実装する。\n",
    "\n",
    "1. ScratchDecesionTreeClassifierDepth1クラスの雛形に含まれるpredictメソッドに書き加える。\n",
    "2. 入力されたデータの値が、学習後の関数を用いて、どの葉ノードのどのクラスに到達するかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
