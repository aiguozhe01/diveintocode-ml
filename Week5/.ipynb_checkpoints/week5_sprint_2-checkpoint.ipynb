{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint_2 機械学習スクラッチ入門\n",
    "\n",
    "\n",
    "# 【問題1】train_test_splitのスクラッチ\n",
    "\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【確認】\n",
    "\n",
    "* train_test_split関数はscikit-learnライブラリ内にある一関数である。\n",
    "* データの前処理の一環として利用する。\n",
    "* 訓練データと検証データに指定した割合にランダムで分割する。\n",
    "* Xとyの配列を変数とし、Xとyの訓練データと検証データをそれぞれ出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. Randomizing\n",
    "        1. Using np.random.shuffle(), shuffle the two arrays.\n",
    "        2. Make pre_shuffle_x, pre_shuffle_y, post_shuffle_x, post_shuffle_y.\n",
    "\n",
    "    2. Dividing (Default: test_size 0.25, train_size 0.75)\n",
    "        1. Using this [tactics](https://stackoverflow.com/questions/58374049/split-a-list-with-a-adjustable-ratio) to split a list.\n",
    "        2. Make 2 splitted lists for train and test for each x and y\n",
    "    3. Return\n",
    "        1. Return value.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Intake parameter X, y and shuffle them.\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    # Split X and y into given ratio.\n",
    "    elements_x = len(X)\n",
    "    middle_x = int(elements_x * train_size)\n",
    "    X_train, X_test = X[:middle_x], X[middle_x:]\n",
    "    # print(x_train, x_test)\n",
    "\n",
    "    elements_y = len(y)\n",
    "    middle_y = int(elements_y * (train_size))\n",
    "    y_train, y_test = y[:middle_y], y[middle_y:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【確認】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]]),\n",
       " [1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 仮データ\n",
    "X, y = np.arange(10).reshape((5, 2)), [1, 2, 3, 4, 5]\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learnの返り値 X_train_sklは\n",
      "[[4 5]\n",
      " [8 9]\n",
      " [0 1]\n",
      " [2 3]]\n",
      "scikit-learnの返り値 X_test_sklは[[6 7]]\n",
      "scikit-learnの返り値 y_train_sklは[4, 3, 1, 2]\n",
      "scikit-learnの返り値 y_testsklは[5]\n",
      "\n",
      "\n",
      "\n",
      "スクラッチの返り値 X_trainは\n",
      "[[4 5]\n",
      " [6 7]\n",
      " [2 3]\n",
      " [8 9]]\n",
      "スクラッチの返り値 X_testは[[0 1]]\n",
      "スクラッチの返り値 y_trainは[5, 1, 4, 3]\n",
      "スクラッチの返り値 y_testは[2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_skl, X_test_skl, y_train_skl, y_test_skl = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"scikit-learnの返り値 X_train_sklは\\n{}\".format(X_train))\n",
    "print(\"scikit-learnの返り値 X_test_sklは{}\".format(X_test))\n",
    "print(\"scikit-learnの返り値 y_train_sklは{}\".format(y_train))\n",
    "print(\"scikit-learnの返り値 y_testsklは{}\".format(y_test)) \n",
    "print()\n",
    "print()\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "print(\"スクラッチの返り値 X_trainは\\n{}\".format(X_train))\n",
    "print(\"スクラッチの返り値 X_testは{}\".format(X_test))\n",
    "print(\"スクラッチの返り値 y_trainは{}\".format(y_train))\n",
    "print(\"スクラッチの返り値 y_testは{}\".format(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "\n",
    "1. ロジスティック回帰（SGDClassifier）を用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "2. SVMを用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "3. 決定木を用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "4. 線形回帰をスクラッチする。\n",
    "    * House Pricesコンペティションのデータセットを利用する。\n",
    "        * train.csvをダウンロード。\n",
    "        * 目的変数：SalePrice\n",
    "        * 説明変数：GrLivArea, YearBuilt\n",
    "    * SGDRegressorクラスを利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【準備】3種類のデータセットを用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# 基データから特定の全種の特徴量を抽出。\n",
    "iris_raw_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "#iris_data = iris_raw_data[['sepal length (cm)', 'petal length (cm)']]\n",
    "\n",
    "# 基データから特定の2品種のみを抽出。\n",
    "iris_raw_species = pd.DataFrame(iris.target, columns=[\"species\"])\n",
    "iris_species = iris_raw_species[iris_raw_species['species'].isin([1, 2])]\n",
    "\n",
    "# 上記2つのデータを結合させる。\n",
    "iris_df = pd.concat([iris_raw_data, iris_species], join='inner', axis=1)\n",
    "\n",
    "X_iris = np.array(iris_df.iloc[:, :4])\n",
    "y_iris = np.array(iris_df.iloc[:, 4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット１\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X_simple1 = X[random_index]\n",
    "y_simple1 = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット２\n",
    "\n",
    "X_simple2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y_simple2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【解答2_1】ロジスティック回帰による学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    ロジスティック回帰による学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SGDClassifierを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "    # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SGDCLassifierを用いて学習する。\n",
    "    lr = SGDClassifier(loss='log')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = lr.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_gradient_descent(X_iris, y_iris, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_3】シンプルデータセット1を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,\n",
       "       -1, -1, -1,  1, -1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1, -1, -1,\n",
       "        1,  1,  1, -1,  1,  1, -1, -1, -1,  1, -1,  1, -1, -1, -1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_gradient_descent(X_simple1, y_simple1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_4】シンプルデータ2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_gradient_descent(X_simple2, y_simple2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【解答2_2】SVMによる学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_function (X, y, train_size):\n",
    "    \"\"\"\n",
    "    SVMによる学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SVCを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "    # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SVCを用いて学習する。\n",
    "    model = SVC(gamma='scale')\n",
    "    model.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = model.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_iris, y_iris, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_3】シンプルデータセット1を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_simple1, y_simple1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_4】シンプルデータ2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_simple2, y_simple2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【解答2_3】決定木による学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "def tree_function (X, y, z):\n",
    "    \"\"\"\n",
    "    決定木による学習・推定まで行う。\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    z : 木の深さ\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. tree.DecisionTreeClassifierを用いて学習する。\n",
    "    2. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 treeを用いて学習する。\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=z)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # Process_1 fit後の推定(predict)を行う。\n",
    "    predicted_test = clf.predict(X)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_iris, y_iris, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_3】シンプルデータセット1を用いての検証¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1,\n",
       "       -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,\n",
       "       -1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,\n",
       "       -1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,\n",
       "       -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1, -1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,\n",
       "        1, -1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
       "        1,  1,  1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "       -1,  1,  1, -1, -1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
       "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1, -1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_simple1, y_simple1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_4】シンプルデータセット2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_simple2, y_simple2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】 回帰問題を解くコードの作成\n",
    "\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答3_4_1】データセットを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "house_df = pd.read_csv('../../HousePrices_train.csv')\n",
    "\n",
    "# 目的変数\n",
    "y_house = np.array(house_df.loc[:, ['SalePrice']])\n",
    "\n",
    "# 説明変数\n",
    "X_house = np.array(house_df.loc[:, ['GrLivArea', 'YearBuilt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答3_4_2】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def linear_regression(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    線形回帰による学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SGDClassifierを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "        # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SGDCLassifierを用いて学習する。\n",
    "    reg = SGDRegressor(max_iter=1000)\n",
    "    reg.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = reg.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182420.918780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180356.580516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183451.710736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175162.310675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177361.933970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>176098.157826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>177719.989975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>181889.298251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>181055.703986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>182267.619863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted_prices\n",
       "0       182420.918780\n",
       "1       180356.580516\n",
       "2       183451.710736\n",
       "3       175162.310675\n",
       "4       177361.933970\n",
       "..                ...\n",
       "287     176098.157826\n",
       "288     177719.989975\n",
       "289     181889.298251\n",
       "290     181055.703986\n",
       "291     182267.619863\n",
       "\n",
       "[292 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推定結果\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "predicted_test = linear_regression(X_house, y_house, 0.8)\n",
    "result = pd.DataFrame(predicted_test, columns=['predicted_prices'])\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
