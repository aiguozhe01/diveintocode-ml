{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【確認】\n",
    "\n",
    "* train_test_split関数はscikit-learnライブラリ内にある一関数である。\n",
    "* データの前処理の一環として利用する。\n",
    "* 訓練データと検証データに指定した割合にランダムで分割する。\n",
    "* Xとyの配列を変数とし、Xとyの訓練データと検証データをそれぞれ出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. Randomizing\n",
    "        1. Using np.random.shuffle(), shuffle the two arrays.\n",
    "        2. Make pre_shuffle_x, pre_shuffle_y, post_shuffle_x, post_shuffle_y.\n",
    "\n",
    "    2. Dividing (Default: test_size 0.25, train_size 0.75)\n",
    "        1. Using this [tactics](https://stackoverflow.com/questions/58374049/split-a-list-with-a-adjustable-ratio) to split a list.\n",
    "        2. Make 2 splitted lists for train and test for each x and y\n",
    "    3. Return\n",
    "        1. Return value.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Cast into np\n",
    "    # np.array(X)\n",
    "    # np.array(y)\n",
    "    \n",
    "    # Intake parameter X, y and shuffle them.\n",
    "    np.random.shuffle(X)\n",
    "    np.random.shuffle(y)\n",
    "    \n",
    "    # Split X and y into given ratio.\n",
    "    elements_x = len(X)\n",
    "    middle_x = int(elements_x * train_size)\n",
    "    X_train, X_test = X[:middle_x], X[middle_x:]\n",
    "    # print(x_train, x_test)\n",
    "\n",
    "    elements_y = len(y)\n",
    "    middle_y = int(elements_y * (train_size))\n",
    "    y_train, y_test = y[:middle_y], y[middle_y:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【確認】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仮データ\n",
    "X, y = np.arange(10).reshape((5, 2)), [1, 2, 3, 4, 5]\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "print(\"返り値 X_trainは\\n{}\".format(X_train))\n",
    "print(\"返り値 X_testは{}\".format(X_test))\n",
    "print(\"返り値 y_trainは{}\".format(y_train))\n",
    "print(\"返り値 y_testは{}\".format(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "\n",
    "1. ロジスティック回帰（SGDClassifier）を用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "2. SVMを用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "3. 決定木を用い、3種類のデータセットを学習・推定するコードを作成する。\n",
    "4. 線形回帰をスクラッチする。\n",
    "    * House Pricesコンペティションのデータセットを利用する。\n",
    "        * train.csvをダウンロード。\n",
    "        * 目的変数：SalePrice\n",
    "        * 説明変数：GrLivArea, YearBuilt\n",
    "    * SGDRegressorクラスを利用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【準備】3種類のデータセットを用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# 基データから特定の全種の特徴量を抽出。\n",
    "iris_raw_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "#iris_data = iris_raw_data[['sepal length (cm)', 'petal length (cm)']]\n",
    "\n",
    "# 基データから特定の2品種のみを抽出。\n",
    "iris_raw_species = pd.DataFrame(iris.target, columns=[\"species\"])\n",
    "iris_species = iris_raw_species[iris_raw_species['species'].isin([1, 2])]\n",
    "\n",
    "# 上記2つのデータを結合させる。\n",
    "iris_df = pd.concat([iris_raw_data, iris_species], join='inner', axis=1)\n",
    "\n",
    "X_iris = np.array(iris_df.iloc[:, :4])\n",
    "y_iris = np.array(iris_df.iloc[:, 4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット１\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X_simple1 = X[random_index]\n",
    "y_simple1 = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット２\n",
    "\n",
    "X_simple2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y_simple2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1】ロジスティック回帰による学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def logistic_regression(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    ロジスティック回帰による学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SGDClassifierを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "    # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SGDCLassifierを用いて学習する。\n",
    "    lr = SGDClassifier(loss='log')\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = lr.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X_iris, y_iris, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_3】シンプルデータセット1を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1,\n",
       "       -1,  1,  1, -1, -1,  1,  1, -1, -1,  1,  1, -1, -1, -1, -1,  1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
       "       -1,  1,  1, -1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,\n",
       "        1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,\n",
       "        1, -1, -1,  1,  1, -1,  1, -1, -1,  1, -1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X_simple1, y_simple1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_1_4】シンプルデータ2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X_simple2, y_simple2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2】SVMによる学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_function (X, y, train_size):\n",
    "    \"\"\"\n",
    "    SVMによる学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SVCを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "    # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SVCを用いて学習する。\n",
    "    model = SVC(gamma='scale')\n",
    "    model.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = model.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_iris, y_iris, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_3】シンプルデータセット1を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_simple1, y_simple1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_2_4】シンプルデータ2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_function(X_simple2, y_simple2, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3】決定木による学習・推定までのコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_1】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "def tree_function (X, y, z):\n",
    "    \"\"\"\n",
    "    決定木による学習・推定まで行う。\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    z : 木の深さ\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. tree.DecisionTreeClassifierを用いて学習する。\n",
    "    2. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 treeを用いて学習する。\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=z)\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # Process_1 fit後の推定(predict)を行う。\n",
    "    predicted_test = clf.predict(X)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_2】Irisデータセットを用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
       "       1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_iris, y_iris, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_3】シンプルデータセット1を用いての検証¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,\n",
       "        1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1,\n",
       "       -1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1, -1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,\n",
       "       -1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,\n",
       "       -1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "       -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,\n",
       "       -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1, -1, -1, -1, -1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,\n",
       "        1, -1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1,\n",
       "        1,  1,  1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "       -1,  1,  1, -1, -1,  1, -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1, -1,  1,  1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1,\n",
       "       -1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "        1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1,  1,  1, -1,  1,\n",
       "       -1,  1, -1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1, -1,  1,\n",
       "       -1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_simple1, y_simple1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答2_3_4】シンプルデータセット2を用いての検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_function(X_simple2, y_simple2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答3_4_1】データセットを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "house_df = pd.read_csv('../../HousePrices_train.csv')\n",
    "\n",
    "# 目的変数\n",
    "y_house = np.array(house_df.loc[:, ['SalePrice']])\n",
    "\n",
    "# 説明変数\n",
    "X_house = np.array(house_df.loc[:, ['GrLivArea', 'YearBuilt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【解答3_4_2】関数構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def linear_regression(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    線形回帰による学習・推定まで行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    predicted_test : ndarray, shape ()\n",
    "    　標準化済みの検証用データ（X_test_std）を用いての推定値\n",
    "    　以降の一致率検証用に用いる。\n",
    "    \n",
    "    Process\n",
    "    ----------\n",
    "    1. 交差検定を行うために、関数scratch_train_test_splitを用いてデータセットを分割する。\n",
    "    2. StandardScalerを用いて学習用データの特徴量を標準化する。\n",
    "    3. SGDClassifierを用いて学習する。\n",
    "    4. predictを用いて推定する。\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Process_1 scratch_train_test_split関数を用いてデータセットを分割する。\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size)\n",
    "    \n",
    "    # 目的変数の1次元化\n",
    "    y_train = np.reshape(y_train,(-1))\n",
    "    y_test = np.reshape(y_test,(-1))\n",
    "    \n",
    "    # Process_2 StandardScalerを用いてX_trainを標準化する。(pipelineを用いての省略も可)\n",
    "    sc = StandardScaler()\n",
    "        # 平均値と標準偏差値の算出\n",
    "    sc.fit(X_train)\n",
    "    \n",
    "        # 標準化\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "    \n",
    "    # Process_3 SGDCLassifierを用いて学習する。\n",
    "    reg = SGDRegressor(max_iter=1000)\n",
    "    reg.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Process_4 fit後の推定(predict)を行う。\n",
    "    predicted_test = reg.predict(X_test_std)\n",
    "    \n",
    "    return predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183342.31739127, 187235.42081144, 186029.89104747, 174551.33864729,\n",
       "       183633.56479899, 185035.38540191, 179629.30492231, 182364.56769937,\n",
       "       176565.75751792, 185713.89535242, 184510.17304226, 178043.0159421 ,\n",
       "       172633.00210822, 175987.75212268, 179230.02709626, 175184.89987197,\n",
       "       180729.24861511, 181817.36984623, 181547.15259196, 184572.81066297,\n",
       "       180947.82099541, 188468.67687698, 187719.81062112, 174530.3532915 ,\n",
       "       187631.25415263, 177920.52589335, 185658.14670142, 181680.27214313,\n",
       "       182123.03208671, 180657.89217207, 176823.02654772, 176453.60092372,\n",
       "       183751.46220127, 187983.45735236, 185638.79837667, 177781.47271252,\n",
       "       181795.40675156, 168920.11526437, 169622.88463277, 182428.33108288,\n",
       "       177189.68937787, 180580.5212719 , 177905.11092289, 181550.40425523,\n",
       "       177867.22158951, 184809.41278365, 188849.09524772, 185810.14810673,\n",
       "       183879.18178986, 174642.50988569, 188193.69655349, 184452.93538413,\n",
       "       173081.94693168, 187078.50831298, 170531.66380016, 183340.68036022,\n",
       "       180860.75353405, 185530.23429126, 190066.61789612, 184831.86474775,\n",
       "       184190.41441568, 181776.036028  , 180415.40121937, 183142.6268651 ,\n",
       "       184329.78604319, 183077.69292116, 186139.89934236, 181769.48790379,\n",
       "       188238.45245775, 167254.62553137, 176347.8444298 , 184307.48210303,\n",
       "       185100.31934586, 172152.86409951, 184715.30832865, 179745.39487079,\n",
       "       180713.32237639, 187676.03245572, 187922.30873877, 182029.07565565,\n",
       "       179419.7474122 , 159688.84332279, 186143.85509547, 177946.7631878 ,\n",
       "       178416.71576589, 186357.17553712, 179465.14020982, 187020.61136267,\n",
       "       181692.92431974, 176137.92367536, 178394.7302724 , 186295.36763134,\n",
       "       187711.60306704, 179386.13227861, 181597.64930431, 177027.18409525,\n",
       "       176333.40719821, 186271.42666012, 175742.45357849, 186026.44656262,\n",
       "       181374.48427753, 185249.68358243, 175805.0911992 , 189726.8516526 ,\n",
       "       167439.43475415, 186886.00280438, 186849.9209248 , 188307.49017873,\n",
       "       186468.18396969, 179416.30292734, 188325.03104968, 186658.73400056,\n",
       "       183703.0913894 , 182879.44660447, 167771.60793813, 181315.29114167,\n",
       "       181461.72216165, 166204.34883598, 179732.91311693, 183476.14103227,\n",
       "       185383.48482461, 185102.59327027, 182306.98919574, 168305.02785186,\n",
       "       179408.5842427 , 175250.17466142, 182296.50771725, 175898.70678476,\n",
       "       186179.57373072, 186268.30062195, 180704.62595289, 185417.75925038,\n",
       "       185484.98951756, 178409.82679618, 184494.90609573, 183974.45680529,\n",
       "       181678.48708815, 191282.96998407, 183183.61983783, 186662.32650935,\n",
       "       186237.81152653, 182481.31694004, 186736.27532348, 172778.92185993,\n",
       "       183553.87517676, 186704.12679819, 190066.61789612, 187327.5697887 ,\n",
       "       183808.67746057, 186842.20224016, 181903.14112204, 176646.74332569,\n",
       "       180903.55396058, 181268.38693811, 187665.67660234, 186648.71899269,\n",
       "       183156.23438176, 181952.17122609, 183386.94767043, 185651.74660115,\n",
       "       174700.87330661, 182629.36259223, 180200.08050235, 182612.65143623,\n",
       "       181654.37569418, 184861.88737255, 189872.77140432, 181125.08195631,\n",
       "       182162.04718289, 182682.49647332, 184201.06631692, 174380.47778667,\n",
       "       176911.56061738, 182595.9178814 , 175728.82366301, 175912.14387867,\n",
       "       180509.35765044, 188560.33698481, 180578.88424085, 186699.55655054,\n",
       "       184679.39687183, 188413.56511934, 187020.61136267, 180759.41926385,\n",
       "       186173.51447595, 171570.6069033 , 186654.28937802, 181816.56253011,\n",
       "       188598.20391937, 184259.11129116, 185860.32637239, 188117.7698628 ,\n",
       "       183416.62944973, 182903.70602237, 183888.3670828 , 173481.0767338 ,\n",
       "       186660.6894783 , 184537.55849833, 188537.69219914, 187676.03245572,\n",
       "       180804.98248422, 181613.23469752, 180158.25781468, 186239.10771208,\n",
       "       182600.36250394, 189789.48927332, 173518.13635225, 186610.51121263,\n",
       "       180819.76056132, 187978.22781253, 180048.56796647, 179477.45154093,\n",
       "       166504.73673899, 188085.13246807, 184429.6537051 , 183802.93665249,\n",
       "       185829.34840754, 190033.00276252, 183555.83065449, 180168.44324531,\n",
       "       187782.27781908, 181961.65256689, 181028.65877925, 187026.69301626,\n",
       "       176179.76876185, 185990.04623636, 180265.99218516, 177926.26670144,\n",
       "       176290.4139501 , 184831.54630106, 186127.61041007, 179605.3639511 ,\n",
       "       183325.94708077, 186316.67143382, 182629.87386049, 181066.37768988,\n",
       "       183868.82593647, 183044.07778757, 188750.54617018, 184320.91919693,\n",
       "       179749.49864783, 178824.00832444, 178671.8588952 , 181738.02106951,\n",
       "       181788.68820461, 187106.04179298, 176918.44958708, 188260.09710573,\n",
       "       172534.45303068, 185653.40603102, 178111.0535254 , 179814.43259178,\n",
       "       174498.86405839, 179767.1875427 , 186645.93380002, 184927.96947812,\n",
       "       177932.81482564, 186150.40321967, 183520.26004317, 189019.4672389 ,\n",
       "       177062.11781321, 187469.55618613, 177651.11595519, 184674.78182654,\n",
       "       183378.08082417, 180958.81374216, 159476.79666786, 181613.23469752,\n",
       "       180737.77461587, 185540.90859132, 182074.32042934, 187730.78096904,\n",
       "       179864.61085745, 186367.50899167, 185576.50160146, 179679.97205741,\n",
       "       184760.55310235, 186844.00969396, 176891.7234232 , 188193.69655349,\n",
       "       186868.09868911, 172175.82733186, 174494.5898586 , 178171.73566838,\n",
       "       179843.11423339, 186313.54539565, 180371.11178572, 188628.20414535,\n",
       "       175953.15925022, 179752.77270993, 181101.14098509, 181469.10000078])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(X_house, y_house, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
