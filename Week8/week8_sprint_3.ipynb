{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fractions import Fraction\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n",
      "(48000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([3, 3, 0, 8, 2, 1, 8, 2, 0, 3, 9, 5, 2, 0, 8, 7, 5, 2, 8, 8],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】重みの初期値を決めるコードの作成\n",
    "\n",
    "1. ニューラルネットワークの各層の重みの初期値を決めるコードを作成する。\n",
    "    * 重みの初期値はガウス（正規）分布による単純な初期化を行う。\n",
    "    * バイアスに関しても同様\n",
    "    * サンプルコードの標準偏差の値sigmaはハイパーパラメータ。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output = 10\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "# W1: (784, 400)\n",
    "\n",
    "#################\n",
    "# he_initialization = np.random.randn(size_l, size_l_1) * np.sqrt(2/size_l_1)\n",
    "# xavier_initialization = np.random.randn(size_l, size_l_1) * np.sqrt(1/size_l_1)\n",
    "# Xavier initialization which considers the size of the network(number of input and output units) while initializing weights.\n",
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】フォワードプロパゲーションの実装\n",
    "\n",
    "1. 三層のニューラルネットワークの**フォワードプロパゲーション**を作成する。\n",
    "    * batch_size = 20 # バッチサイズ\n",
    "    * n_features = 784 # 特徴量の数\n",
    "    * n_nodes1 = 400 # 1層目のノード数\n",
    "    * n_nodes2 = 200 # 2層目のノード数\n",
    "    * n_output = 10 # 出力のクラス数（3層目のノード数）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def input_sum(inputs, weights):\n",
    "    \"\"\"\n",
    "    入力和を返す関数\n",
    "    \"\"\"\n",
    "\n",
    "def sigmoid(A):\n",
    "    # return Fraction(1, 1 + np.exp(A))\n",
    "    return 1 / np.exp(A)\n",
    "\n",
    "def hyper_tan(A):\n",
    "    answer = (np.exp(A)-np.exp(A)) /  (exp(A)+exp(A))\n",
    "    return answer\n",
    "    \n",
    "def soft_max(A_3):\n",
    "    '''\n",
    "    A_3 = k番目のクラスにあたる前の層からのベクトル (batch_size, )\n",
    "    '''\n",
    "    # 入力値の中で最大値を取得\n",
    "    max_value = np.max(A_3)\n",
    "    \n",
    "    # オーバーフロー対策として、最大値max_valueを引く。こうすることで値が小さくなる。\n",
    "    exp_A_3 = np.exp(A_3 - max_value);\n",
    "    sum_exp_A_3 = np.sum(exp_A_3)\n",
    "    \n",
    "    # answer = Fraction(exp_A_3, sum_exp_A_3)\n",
    "    answer= exp_A_3 / sum_exp_A_3\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, sigma=0.01, batch_size=20, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10):\n",
    "    \"\"\"\n",
    "    順方向処理をする関数\n",
    "    3層ニューラルネットワークを対象とした、入力から出力への処理（フォワード方向への処理）を実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      入力データ\n",
    "    sigma : float\n",
    "      ガウス（正規分布）分布の標準偏差（default=0.01）\n",
    "    batch_size : int（default=20）\n",
    "      バッチサイズ\n",
    "    n_features : int（default=784）\n",
    "      特徴量の数\n",
    "    n_nodes1 : int（default=400）\n",
    "    　1層目のノード数\n",
    "    n_nodes2 : int（default=200）\n",
    "    　2層目のノード数\n",
    "    n_output : int（default=10）\n",
    "    　出力のクラス数（3層目のノード数）\n",
    "      \n",
    "    Returns\n",
    "    ----------\n",
    "    final_output : 次の形のndarray, shape (batch_size, n_output)\n",
    "    \"\"\"    \n",
    "    # バッチの抽出\n",
    "    feature_vector = X[0][:batch_size, :]\n",
    "    \n",
    "    # 重みの初期化\n",
    "    W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "    W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "    W3 = sigma * np.random.randn(n_nodes2, n_output)    \n",
    "    # W1.shape : (784, 400)\n",
    "    \n",
    "    # バイアスの初期化\n",
    "    bias_1 = np.full((n_nodes1, ), 0.01)\n",
    "    bias_2 = np.full((n_nodes2, ), 0.01)\n",
    "    bias_3 = np.full((n_output, ), 0.01)\n",
    "    \n",
    "    output_1 = np.matmul(feature_vector, W1) + bias_1\n",
    "    # (batch_size, n_nodes1) = (batch_size, n_features) * (n_features, n_nodes1) + (n_nodes1, )\n",
    "    output_1_mid = sigmoid(output_1)\n",
    "    \n",
    "    output_2 = np.matmul(output_1_mid, W2) + bias_2\n",
    "    # (batch_size, n_nodes2) = (batch_size, n_nodes1) * (n_nodes1, n_nodes2) + (n_nodes2, )\n",
    "    output_2_mid = sigmoid(output_2)\n",
    "    \n",
    "    output_3 = np.matmul(output_2_mid, W3) + bias_3\n",
    "    # (batch_size, n_output) = (batch_size, n_nodes2) * (n_nodes2, n_output) + (n_output, )\n",
    "    \n",
    "    final_output = soft_max(output_3)\n",
    "    # print(final_output.shape, type(final_output))\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00480394, 0.00476361, 0.00595328, 0.00502035, 0.00520196,\n",
       "       0.00430025, 0.00499428, 0.00522441, 0.00430011, 0.00544071])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = get_mini_batch[0]\n",
    "final_output = forward_propagation(X)\n",
    "final_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】交差エントロピー誤差の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t, batch_size):\n",
    "    delta = 1e-7\n",
    "    return -(np.sum(t * np.log(y + delta))) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.289953854249503"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = forward_propagation(X)\n",
    "batch_size = 20\n",
    "y_train_sample = y_train_one_hot[:batch_size, :]\n",
    "\n",
    "cross_entropy_error(final_output, y_train_sample, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】バックプロパゲーションの実装\n",
    "勾配 \n",
    "$∂L∂Wi$ や $∂L∂Bi$ を求めるために、バックプロパゲーションを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corss_entropy_error = cross_entropy_error(final_output, y_train_sample, 20)\n",
    "Z3 = final_output # ソフトマックス関数の出力 (batch_size, n_nodes2) : (20, 200)\n",
    "Y = y_train_one_hot[:batch_size, :n_output] # 正解ラベル (batch_size, n_output) : (20, 10)\n",
    "np.sum(Z3 - Y)\n",
    "\n",
    "Z2 = output_2_mid # 2層目の活性化関数の出力 (batch_size, n_nodes2):(20, 200)\n",
    "\n",
    "def back_propagation():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【訂正事項】\n",
    "\n",
    "【問題4】の「3層目」の数式の説明欄\n",
    "* 誤）$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_nodes2)\n",
    "* 正）$Z_{3}$ : ソフトマックス関数の出力 (batch_size, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
