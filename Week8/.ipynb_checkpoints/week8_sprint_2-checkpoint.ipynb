{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習\n",
    "\n",
    "## 【考察】\n",
    "\n",
    "**アンサンブル学習とは・・・**\\\n",
    "複数の学習モデルを組み合わせる手法。\n",
    "* 下階層：ベースモデル（base/weak learner/ genelizer）\n",
    "* 上階層：メタモデル（meta learner/stacker）\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "* バギング：訓練データを分割して、複数の決定木モデルの推定値を評価する方法。\n",
    "* ブレンディング：複数のモデルの推定値を使って評価する方法\n",
    "* スタッキング：ブレンディングとバギングのハイブリッド手法。複数のモデルを用い、訓練データを分割して評価する方法。\n",
    "\n",
    "(Bagging)\n",
    "        * for 決定木\n",
    "        * 過学習（訓練データに過剰適合しがち）\n",
    "        * so 汎化誤差（generalization error）を減らしたい。\n",
    "        * generalization error = variance（モデルの複雑さ）+ bias（真の関数とモデルのずれ）** 2 + noise\n",
    "        * therefore Baggingが提案される。（単一の決定木だと高くなりがちなvarianceを下げる事ができる。\n",
    "            1. 訓練データから離散一様分布に従い、ランダムな標本再抽出（bootstrap sampling）\n",
    "            2. 分割した各サブセットに対して決定木を当てはめ、複数の決定木の結果を得る。\n",
    "            3. 最後に多数決（回帰ならば平均）を行う。\n",
    "            4. そもそも上記のアルゴリズムに特徴量サンプリングも追加して、RandomForestとなる。\n",
    "            \n",
    "        * for RandomForest\n",
    "        * bootstrap法で作成した各々の決定木同士の相関 > 分岐で異なる特徴量を選ぶ決定木を生成するRandomForest\n",
    "        * 結果、RandomForestだとvariance（分散）が下がり、Baggingより汎化性能（未知のテストデータに対する識別能力）が高くなる。\n",
    "\n",
    "(Blending)\n",
    "        * Bagging/RandomForestと違い、異なる予測モデルを組み合わせる。\n",
    "            * 異なる予測モデル、特徴量、訓練データ、パラメータ（多数決、平均値、最大値、最小値 etc）\n",
    "            \n",
    "(Stacking)\n",
    "        * 予測モデルの積み重ね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "疑問点\n",
    "* 説明変数をsplitしたが、目的変数もsplitが必要ではないのか？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# データ分割用\n",
    "from sklearn.model_selection import train_test_split\n",
    "# MSE算出用\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 線形回帰用\n",
    "from sklearn import datasets, linear_model\n",
    "# 決定木用\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# SVR用\n",
    "from sklearn.svm import SVR\n",
    "# ロジスティック回帰用\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# ランダムフォレスト用\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 主成分分析器用\n",
    "from sklearn.decomposition import PCA \n",
    "# 標準化用\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 標準化と学習モデルを一元化するため\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvファイルを読み込む\n",
    "data_set = pd.read_csv('..\\Week4\\house_prices_train.csv')\n",
    "\n",
    "# 目的変数と説明変数とで区分する。\n",
    "input_data = data_set[[\"GrLivArea\", \"YearBuilt\"]]\n",
    "target_data = data_set[[\"SalePrice\"]]\n",
    "\n",
    "# 説明変数を8:2で分割する。\n",
    "input_train, input_test = train_test_split(input_data, test_size=0.2, random_state=0)\n",
    "\n",
    "# 目的変数を8:2で分割する。\n",
    "target_train, target_test = train_test_split(target_data, test_size=0.2, random_state=0)\n",
    "\n",
    "########\n",
    "# 標準化のインスタンス化\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "sscaler_input = sscaler.fit(input_train)\n",
    "input_train_ss = sscaler_input.transform(input_train)\n",
    "input_test_ss = sscaler_input.transform(input_test)\n",
    "\n",
    "sscaler_target = sscaler.fit(target_train)\n",
    "target_train_ss = sscaler_target.transform(target_train)\n",
    "target_test_ss = sscaler_target.transform(target_test)\n",
    "########\n",
    "\n",
    "# 主成分分析\n",
    "pca = PCA()\n",
    "pca_default = pca.fit(input_train)\n",
    "pca_ss = pca.fit(input_train_ss)\n",
    "\n",
    "input_train_pca = pca_default.transform(input_train)\n",
    "input_train_ss_pca = pca_ss.transform(input_train_ss)\n",
    "\n",
    "input_test_pca = pca_default.transform(input_test)\n",
    "input_test_ss_pca = pca_ss.transform(input_test_ss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ブレンディングのスクラッチ実装\n",
    "\n",
    "ブレンディングを3通りスクラッチ実装せよ。\n",
    "\n",
    "* 比較対象として、単一モデルも用意する。\n",
    "* 比較数値は精度の上下\n",
    "    * 例）精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さいこと。\n",
    "----------    \n",
    "    \n",
    "**比較3通り**\n",
    "\n",
    "1. ロジスティック回帰 vs ロジスティック回帰（標準化）\n",
    "2. ロジスティック回帰 vs ロジスティック回帰（標準化+主成分分析）\n",
    "3. ロジスティック回帰 vs ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰の平均二乗誤差（MSE）は: 2.94207e+09\n",
      "線形回帰の標準化済み平均二乗誤差（MSE）は：2.94207e+09\n",
      "線形回帰の標準化+PCA済み平均二乗誤差（MSE）は：2.94207e+09\n"
     ]
    }
   ],
   "source": [
    "# コントロール対照\n",
    "# 線形回帰モデルをインスタンス化\n",
    "linear_regr = linear_model.LinearRegression()\n",
    "linear_regr_ss = linear_model.LinearRegression()\n",
    "linear_regr_ss_pca = linear_model.LinearRegression()\n",
    "\n",
    "# モデルを学習させる。\n",
    "linear_regr.fit(input_train, target_train)\n",
    "linear_regr_ss.fit(input_train_ss, target_train)\n",
    "linear_regr_ss_pca.fit(input_train_ss_pca, target_train)\n",
    "\n",
    "# 学習後のモデルを用い、推測を行う。\n",
    "target_predict = linear_regr.predict(input_test)\n",
    "target_predict_ss = linear_regr_ss.predict(input_test_ss)\n",
    "target_predict_ss_pca = linear_regr_ss_pca.predict(input_test_ss_pca)\n",
    "\n",
    "\n",
    "# MSEを算出する前に、推測結果の平均値を出す！！！\n",
    "# The mean squared error\n",
    "linear_regr_mse = mean_squared_error(target_test, target_predict)\n",
    "linear_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
    "linear_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
    "\n",
    "print('線形回帰の平均二乗誤差（MSE）は: %.5e'% linear_regr_mse)\n",
    "print('線形回帰の標準化済み平均二乗誤差（MSE）は：%.5e'% linear_regr_ss_mse)\n",
    "print('線形回帰の標準化+PCA済み平均二乗誤差（MSE）は：%.5e'% linear_regr_ss_pca_mse)\n",
    "\n",
    "# plot outputs\n",
    "#\n",
    "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
    "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
    "#\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "#\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "決定木（回帰）の平均二乗誤差（MSE）は: 3.00917e+09\n",
      "決定木（回帰）の標準化済み平均二乗誤差（MSE）は：3.01586e+09\n",
      "決定木（回帰）の標準化+PCA済み平均二乗誤差（MSE）は：2.94207e+09\n"
     ]
    }
   ],
   "source": [
    "# 決定木（回帰）のMSEを算出\n",
    "\n",
    "# 決定木モデルをインスタンス化\n",
    "tree_regr = DecisionTreeRegressor(random_state=0)\n",
    "tree_regr_ss = DecisionTreeRegressor(random_state=0)\n",
    "tree_regr_ss_pca = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "# モデルを学習させる。\n",
    "tree_regr.fit(input_train, target_train)\n",
    "tree_regr_ss.fit(input_train_ss, target_train)\n",
    "tree_regr_ss_pca.fit(input_train_ss_pca, target_train)\n",
    "\n",
    "# 学習後のモデルを用い、推測を行う。\n",
    "target_predict = tree_regr.predict(input_test)\n",
    "target_predict_ss = tree_regr_ss.predict(input_test_ss)\n",
    "target_precict_ss_pca = tree_regr_ss_pca.predict(input_test_ss_pca)\n",
    "\n",
    "# The mean squared error\n",
    "tree_regr_mse = mean_squared_error(target_test, target_predict)\n",
    "tree_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
    "tree_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
    "\n",
    "print(f'決定木（回帰）の平均二乗誤差（MSE）は:{tree_regr_mse: .5e}')\n",
    "print(f'決定木（回帰）の標準化済み平均二乗誤差（MSE）は：%.5e'% tree_regr_ss_mse)\n",
    "print(f'決定木（回帰）の標準化+PCA済み平均二乗誤差（MSE）は：%.5e'% tree_regr_ss_pca_mse)\n",
    "\n",
    "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
    "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVRモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVRの平均二乗誤差（MSE）は: 2.942e+09\n",
      "SVRのPCA済み平均二乗誤差（MSE）は： 2.942e+09\n",
      "SVRの標準化済み平均二乗誤差（MSE）は：7.092e+09\n",
      "SVRの標準化+PCA済み平均二乗誤差（MSE）は：7.092e+09\n"
     ]
    }
   ],
   "source": [
    "# SVRのMSEを算出\n",
    "\n",
    "# SVRモデルをインスタンス化\n",
    "sv_regr = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
    "sv_regr_pca = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
    "sv_regr_ss = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
    "sv_regr_ss_pca = SVR(C=1.0, kernel='linear', epsilon=0.1)\n",
    "\n",
    "# モデルを学習させる。\n",
    "sv_regr.fit(input_train, target_train.iloc[:, 0]) # SVR的に学習する際の目的変数は1dが望ましいので、pandas.series化する。\n",
    "sv_regr_pca.fit(input_train_pca, target_train.iloc[:, 0])\n",
    "sv_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
    "sv_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
    "\n",
    "\n",
    "# 学習後のモデルを用い、推測を行う。\n",
    "target_predict = sv_regr.predict(input_test)\n",
    "target_predict_pca = sv_regr_pca.predict(input_test_pca)\n",
    "target_predict_ss = sv_regr_ss.predict(input_test_ss)\n",
    "target_predict_ss_pca = sv_regr_ss_pca.predict(input_test_ss_pca)\n",
    "\n",
    "# The mean squared error\n",
    "sv_regr_mse = mean_squared_error(target_test, target_predict)\n",
    "sv_regr_pca_mse = mean_squared_error(target_test, target_predict)\n",
    "sv_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
    "sv_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
    "\n",
    "print(f'SVRの平均二乗誤差（MSE）は:{sv_regr_mse: .3e}')\n",
    "print(f'SVRのPCA済み平均二乗誤差（MSE）は：{sv_regr_pca_mse: .3e}')\n",
    "print(f'SVRの標準化済み平均二乗誤差（MSE）は：%.3e'% sv_regr_ss_mse)\n",
    "print(f'SVRの標準化+PCA済み平均二乗誤差（MSE）は：%.3e'% sv_regr_ss_pca_mse)\n",
    "\n",
    "\n",
    "# plt.scatter(input_test.iloc[:,0], target_test, color='black')\n",
    "# plt.plot(input_test.iloc[:,0].sort_values(), np.sort(target_predict, axis=0), color='blue', linewidth=3)\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.title('GrLivArea vs SalePrice')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰の平均二乗誤差（MSE）は: 5.471e+09\n",
      "ロジスティック回帰の標準化済み平均二乗誤差（MSE）は：3.836e+09\n",
      "ロジスティック回帰の標準化+PCA済み平均二乗誤差（MSE）は：4.878e+09\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰のMSEを算出\n",
    "\n",
    "# ロジスティック回帰モデルをインスタンス化\n",
    "log_regr = LogisticRegression(random_state=0)\n",
    "log_regr_ss = LogisticRegression(random_state=0)\n",
    "log_regr_ss_pca = LogisticRegression(random_state=0)\n",
    "\n",
    "# モデルを学習させる。\n",
    "log_regr.fit(input_train, target_train.iloc[:, 0])\n",
    "log_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
    "log_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
    "\n",
    "# 学習後のモデルを用い、推測を行う。\n",
    "target_predict = log_regr.predict(input_test)\n",
    "target_predict_ss = log_regr_ss.predict(input_test_ss)\n",
    "target_predict_ss_pca = log_regr_ss.predict(input_test_ss_pca)\n",
    "\n",
    "# The mean squared error\n",
    "log_regr_mse = mean_squared_error(target_test, target_predict)\n",
    "log_regr_ss_mse = mean_squared_error(target_test, target_predict_ss)\n",
    "log_regr_ss_pca_mse = mean_squared_error(target_test, target_predict_ss_pca)\n",
    "\n",
    "print(f'ロジスティック回帰の平均二乗誤差（MSE）は:{log_regr_mse: .3e}')\n",
    "print(f'ロジスティック回帰の標準化済み平均二乗誤差（MSE）は：%.3e'% log_regr_ss_mse)\n",
    "print(f'ロジスティック回帰の標準化+PCA済み平均二乗誤差（MSE）は：%.3e'% log_regr_ss_pca_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレストモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ランダムフォレストの平均二乗誤差（MSE）は: 2.959e+09\n",
      "ランダムフォレストの標準化済み平均二乗誤差（MSE）は：2.956e+09\n",
      "ランダムフォレストの標準化+PCA済み平均二乗誤差（MSE）は2.474e+09\n"
     ]
    }
   ],
   "source": [
    "# ランダムフォレストのMSEを算出\n",
    "\n",
    "# ランダムフォレストモデルをインスタンス化\n",
    "forest_regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "forest_regr_ss = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "forest_regr_ss_pca = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "# モデルを学習させる。\n",
    "forest_regr.fit(input_train, target_train.iloc[:, 0])\n",
    "forest_regr_ss.fit(input_train_ss, target_train.iloc[:, 0])\n",
    "forest_regr_ss_pca.fit(input_train_ss_pca, target_train.iloc[:, 0])\n",
    "\n",
    "# 学習後のモデルを用い、推測を行う。\n",
    "forest_target_predict = forest_regr.predict(input_test)\n",
    "forest_target_predict_ss = forest_regr_ss.predict(input_test_ss)\n",
    "forest_target_predict_ss_pca = forest_regr_ss_pca.predict(input_test_ss_pca)\n",
    "\n",
    "# The mean squared error\n",
    "forest_regr_mse = mean_squared_error(target_test, forest_target_predict)\n",
    "forest_regr_ss_mse = mean_squared_error(target_test, forest_target_predict_ss)\n",
    "forest_regr_ss_pca_mse = mean_squared_error(target_test, forest_target_predict_ss_pca)\n",
    "\n",
    "print(f'ランダムフォレストの平均二乗誤差（MSE）は:{forest_regr_mse: .3e}')\n",
    "print(f'ランダムフォレストの標準化済み平均二乗誤差（MSE）は：%.3e'% forest_regr_ss_mse)\n",
    "print(f'ランダムフォレストの標準化+PCA済み平均二乗誤差（MSE）は%.3e'% forest_regr_ss_pca_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全モデルの作表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>sscaler</th>\n",
       "      <th>sscaler+PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_reg</th>\n",
       "      <td>2.942067e+09</td>\n",
       "      <td>2.942067e+09</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>3.009170e+09</td>\n",
       "      <td>3.015860e+09</td>\n",
       "      <td>2.942067e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>2.941629e+09</td>\n",
       "      <td>7.092013e+09</td>\n",
       "      <td>7.092013e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_reg</th>\n",
       "      <td>5.471145e+09</td>\n",
       "      <td>3.836195e+09</td>\n",
       "      <td>4.878052e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>2.958781e+09</td>\n",
       "      <td>2.956401e+09</td>\n",
       "      <td>2.473558e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 default       sscaler   sscaler+PCA\n",
       "linear_reg  2.942067e+09  2.942067e+09  2.942067e+09\n",
       "tree        3.009170e+09  3.015860e+09  2.942067e+09\n",
       "SVR         2.941629e+09  7.092013e+09  7.092013e+09\n",
       "log_reg     5.471145e+09  3.836195e+09  4.878052e+09\n",
       "forest      2.958781e+09  2.956401e+09  2.473558e+09"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.zeros(15).reshape(5, 3),\n",
    "                 columns=['default', 'sscaler', 'sscaler+PCA'],\n",
    "                 index=['linear_reg', 'tree', 'SVR', 'log_reg', 'forest'])\n",
    "df.loc['linear_reg'] = [linear_regr_mse, linear_regr_ss_mse, linear_regr_ss_pca_mse]\n",
    "df.loc['tree'] = [tree_regr_mse, tree_regr_ss_mse, tree_regr_ss_pca_mse]\n",
    "df.loc['SVR'] = [sv_regr_mse, sv_regr_ss_mse, sv_regr_ss_pca_mse]\n",
    "df.loc['log_reg'] = [log_regr_mse, log_regr_ss_mse, log_regr_ss_pca_mse]\n",
    "df.loc['forest'] = [forest_regr_mse, forest_regr_ss_mse, forest_regr_ss_pca_mse]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰の平均二乗誤差（MSE）は: 5.471e+09\n",
      "比較対象①ロジスティック回帰（標準化）のMSEは：3.836e+09\n",
      "比較対象②ロジスティック回帰（標準化+主成分分析）の平均MSEは：4.878e+09\n",
      "比較対象③ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレストの平均MSEは：3.465e+09\n",
      "\n",
      "結論：線形回帰のみのモデルがMSE値も低くかった。\n"
     ]
    }
   ],
   "source": [
    "# コントロール対象\n",
    "print('ロジスティック回帰の平均二乗誤差（MSE）は: %.3e'% log_regr_mse)\n",
    "\n",
    "# ロジスティック回帰前の標準化\n",
    "print('比較対象①ロジスティック回帰（標準化）のMSEは：%.3e'% log_regr_ss_mse)\n",
    "\n",
    "# ロジスティック回帰前に標準化と主成分分析\n",
    "print('比較対象②ロジスティック回帰（標準化+主成分分析）の平均MSEは：%.3e'% log_regr_ss_pca_mse)\n",
    "\n",
    "# 線形回帰+決定木+SVR+ロジスティック回帰+ランダムフォレストの平均MSE\n",
    "set_3 = linear_regr_mse, tree_regr_mse, sv_regr_mse, log_regr_mse, forest_regr_mse\n",
    "print('比較対象③ロジスティック回帰 & 線形回帰 & 決定木 & SVR（線形カーネル）& ランダムフォレストの平均MSEは：%.3e'% np.mean(set_3))\n",
    "print()\n",
    "print(\"結論：線形回帰のみのモデルがMSE値も低くかった。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】バギングのスクラッチ実装\n",
    "\n",
    "バギングをスクラッチ実装せよ。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
